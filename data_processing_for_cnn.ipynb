{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes fire-specific data saved in tif files or pickle files, along with weather data covering the period the fire burned, and produces data that can tain a CNN. The data is saved to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import boto3\n",
    "import io\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# s3 config\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# name of directory with fire tif files\n",
    "tif_directory = \"data\"\n",
    "\n",
    "# name of directory with weather data\n",
    "weather_directory = 'weather_data'\n",
    "\n",
    "# name of fire direction file\n",
    "direction_file = 'BBdirectionCA'\n",
    "\n",
    "# name of fire speed file\n",
    "speed_file = 'BBspeedCA'\n",
    "\n",
    "# weather and fire data to include in model\n",
    "rainint = True\n",
    "raintot = False\n",
    "high_t = True\n",
    "low_t = True\n",
    "humidity = True\n",
    "wind_speed = True\n",
    "wind_direction = True\n",
    "cloud_cover = False\n",
    "fire_direction = False\n",
    "fire_speed = False\n",
    "\n",
    "weather_variables = {\n",
    "    'rainint': rainint, \n",
    "    'raintot': raintot, \n",
    "    'High T': high_t, \n",
    "    'Low T': low_t, \n",
    "    'Humidity': humidity, \n",
    "    'Wind Speed': wind_speed, \n",
    "    'Wind Direction': wind_direction, \n",
    "    'Cloud Cover': cloud_cover,\n",
    "    'Fire Direction': fire_direction,\n",
    "    'Fire Speed': fire_speed\n",
    "}\n",
    "\n",
    "weather_vars = []\n",
    "\n",
    "for k, v in weather_variables.items():\n",
    "    if v == True:\n",
    "        weather_vars.append(k)\n",
    "\n",
    "#####################\n",
    "## HYPERPARAMETERS ##\n",
    "#####################\n",
    "\n",
    "# scale the weather data - yea or nay\n",
    "normalized_weather = True\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# multiplier for amount of zero-labeled data we want to add to dataset\n",
    "labeled_multiplier = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download files from S3 to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_fire_data_from_s3(year, tif_directory):\n",
    "    '''\n",
    "    Pull files from S3 for the provided year and save to local directory\n",
    "    '''\n",
    "    \n",
    "    file_names = [\n",
    "        \"BBdayofburnCA.tif\",\n",
    "        \"BBdirectionCA.tif\",\n",
    "        \"BBfireid.tif\",\n",
    "        \"BBfirelineCA.tif\",\n",
    "        \"BBspeedCA.png\",\n",
    "        \"BBspeedCA.tif\",\n",
    "        \"ignitioncrop.pickle\",\n",
    "        \"polygoncrop.pickle\"\n",
    "    ]\n",
    "        \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    for f in file_names:\n",
    "        key = \"GlobalFire/\" + str(year) + \"/\" + f\n",
    "        path = '/home/ubuntu/wildfireplus/data/' + f\n",
    "        \n",
    "        s3.Bucket('hotzone').download_file(key, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_weather_data_from_s3(year, weather_directory):\n",
    "    '''\n",
    "    Pull files from S3 for the provided year and save to local directory\n",
    "    '''\n",
    "    \n",
    "    file_name = \"weather_data.pickle\"\n",
    "        \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    key = \"BayAreaWeather/\" + str(year) + \"/\" + file_name\n",
    "    path = '/home/ubuntu/wildfireplus/weather_data/' + file_name\n",
    "        \n",
    "    s3.Bucket('hotzone').download_file(key, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Dataset Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(directory):\n",
    "    '''\n",
    "    Process the dataset in the supplied directory and return matrices of which pixels belong to which fire and \n",
    "    which day of the year the pixel was on fire.\n",
    "    \n",
    "    Args: \n",
    "        - directory: name of directory with tif files\n",
    "    Returns: \n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "\n",
    "    # convert to np array\n",
    "    fire_id = Image.open(tiff_dict['BBfireid'])\n",
    "    fire_id = np.array(fire_id)\n",
    "    fire_id[fire_id == -9999] = 0\n",
    "\n",
    "    fireline = Image.open(tiff_dict['BBfirelineCA'])\n",
    "    fireline = np.array(fireline)\n",
    "    fireline[fireline == -9999] = 0\n",
    "\n",
    "    # get list of unique fire_ids\n",
    "    fire_ids = set()\n",
    "\n",
    "    for row in fire_id:\n",
    "        for val in row:\n",
    "            fire_ids.add(val)\n",
    "\n",
    "    # remove 0 from fire_ids set because it does not denote a fire\n",
    "    fire_ids.remove(0)\n",
    "\n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        id = str(id)\n",
    "        fire_data_dict[id] = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        indices = np.where(fire_id == id, 1, 0)\n",
    "        fire_data_dict[str(id)] = indices\n",
    "        \n",
    "    return fire_data_dict, fireline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_matrices(data_dict, fireline):\n",
    "    '''\n",
    "    Create matrices for each fire_id that show were the fire was on a given day during the year.\n",
    "    \n",
    "    Args:\n",
    "        - data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    '''\n",
    "    \n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for key, val in data_dict.items():\n",
    "        data = {}\n",
    "                \n",
    "        for y in range(1, 366):\n",
    "            mask = ((fireline == y) & (val == 1))\n",
    "            mask = mask.astype(int)\n",
    "        \n",
    "            if np.sum(mask) > 0:\n",
    "                data[str(y)] = mask\n",
    "        \n",
    "        fire_data_dict[key] = data\n",
    "        \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_pairs(fire_data_dict):\n",
    "    '''\n",
    "    Create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    the fire was on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    Returns:\n",
    "        - train_labels: a list of sets where the first value of the set is a one-hot encoded 2D array of fire \n",
    "        spread on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2:\n",
    "        [\n",
    "            (one-hot encoded 2D array of fire spread on that day_1, one-hot encoded 2D array of fire spread on day_2),\n",
    "            (one-hot encoded 2D array of fire spread on that day_2, one-hot encoded 2D array of fire spread on day_3),\n",
    "        ]\n",
    "    '''\n",
    "    \n",
    "    train_labels = []\n",
    "\n",
    "    for key, value in fire_data_dict.items():\n",
    "        burn_matrices = list(value.values())\n",
    "        day_of_year = list(value.keys())\n",
    "        \n",
    "        for index, day in enumerate(burn_matrices):\n",
    "\n",
    "            if index < len(burn_matrices) - 1:\n",
    "                day_1 = burn_matrices[index]\n",
    "                day_2_index = index + 1\n",
    "                day_2 = burn_matrices[day_2_index]\n",
    "                \n",
    "                doy = day_of_year[day_2_index]\n",
    "                \n",
    "                pair = (day_1, day_2)\n",
    "                train_labels.append((doy, pair))\n",
    "\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_tiff(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied tiff file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that tiff file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of tiff file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['BBdayofburnCA'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert tif of interest to np array\n",
    "    fire_data_mat = Image.open(tiff_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Direction'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_png(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied png file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that png file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of png file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "    png_files = []\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.png'):\n",
    "            png_files.append(path + '/' + f)\n",
    "    \n",
    "    tiff_dict = {}\n",
    "    png_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "    \n",
    "    for f in png_files:\n",
    "        k = f.split('/')[-1].split('.png')[0]\n",
    "        png_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['BBdayofburnCA'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert png of interest to np array\n",
    "    fire_data_mat = Image.open(png_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Speed'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dicts(dict_1, dict_2):\n",
    "    '''\n",
    "    A helper function to combine the values of two dictionaries that have the same keys.\n",
    "    \n",
    "    Args:\n",
    "        - dict_1: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "        - dict_2: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "    Returns:\n",
    "        - dict_2: combined dictionary of dict_1 and dict_2\n",
    "    '''\n",
    "      \n",
    "    for k, v in dict_1.items():\n",
    "        for att, mat in v.items():\n",
    "            dict_2[k][att] = mat\n",
    "            \n",
    "    return dict_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_dict(directory, normalized_weather, weather_vars, fire_data_dict):\n",
    "    '''\n",
    "    Create a dictionary of weather data from a pickled file\n",
    "    Args:\n",
    "        - directory: path to weather pickle file\n",
    "        - normalized_weather: True/False to scale using max value\n",
    "        - weather_vars: list of weather variables to include in model\n",
    "    Returns:\n",
    "        - weather_data: dictionary of key (day of year) and value (dictionary of key (weather parameter) \n",
    "        and value (matrix of value for each pixel))\n",
    "        - max_values: a list of max values for each weather feature to use to normalize data\n",
    "    '''\n",
    "\n",
    "    path = os.path.abspath(directory)\n",
    "    \n",
    "    weather_file = ''\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.pickle'):\n",
    "            weather_file = path + '/' + f\n",
    "    \n",
    "    weather = pd.read_pickle(weather_file)\n",
    "    \n",
    "    weather_dict = {}\n",
    "    \n",
    "    for k, v in weather.items():\n",
    "        weather_dict[k] = {}\n",
    "        \n",
    "        for att, matrix in v.items():\n",
    "            if att in weather_vars:\n",
    "                \n",
    "                # scale to kelvin\n",
    "                if att in ['High T', 'Low T']:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    mat += 273.15\n",
    "                    weather_dict[k][att] = mat\n",
    "                else:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    weather_dict[k][att] = mat\n",
    "     \n",
    "    weather_data = {}\n",
    "\n",
    "    for k, v in weather_dict.items():\n",
    "        doy = dt.strptime(k, \"%Y-%m-%d\").strftime(\"%-j\")\n",
    "        weather_data[doy] = v\n",
    "        \n",
    "    # add in fire direction and speed\n",
    "    for k, v in fire_data_dict.items():\n",
    "        for att, mat in v.items():\n",
    "            weather_data[k][att] = mat\n",
    "    \n",
    "    # scale weather data\n",
    "    vals = list(weather_data.values())[0]\n",
    "    weather_atts = list(vals.keys())\n",
    "    max_values = dict.fromkeys(weather_atts, 0)\n",
    "    \n",
    "    if normalized_weather == True:\n",
    "        \n",
    "        for k, v in weather_dict.items():\n",
    "\n",
    "            for weather_att, matrix in v.items():\n",
    "                max_val = matrix.max()\n",
    "                if max_val > max_values[weather_att]:\n",
    "                    max_values[weather_att] = max_val\n",
    "    \n",
    "    return weather_data, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(max_values, normalized_weather, day_of_year, x, y):\n",
    "    '''\n",
    "    Fetch weather data for the relevant day and pixel.\n",
    "    \n",
    "    Args:\n",
    "        - max_values: list of max_values for each weather features\n",
    "        - normalized_weather: whether the weather data should be normalized - true/false\n",
    "        - day_of_year: day of the year (1-365)\n",
    "        - x: x-coordinate of matrix\n",
    "        - y: y-coordinate of matrix\n",
    "    Returns:\n",
    "        - weather_list: an array of relevant weather data for that pixel\n",
    "    '''\n",
    "    \n",
    "    weather_list = []\n",
    "    \n",
    "    day_weather = weather_data.get(day_of_year)\n",
    "\n",
    "    if day_weather is None:\n",
    "        return None\n",
    "    else:\n",
    "        for k, v in day_weather.items():\n",
    "            if normalized_weather == True:\n",
    "                max_val = max_values.get(k, 1)\n",
    "                \n",
    "                try:\n",
    "                    val = v[x,y]\n",
    "                    value = val/max_val\n",
    "                    \n",
    "                    if math.isnan(value):\n",
    "                        weather_list.append(0)\n",
    "                    else:\n",
    "                        weather_list.append(value)\n",
    "                except IndexError:\n",
    "                    return None\n",
    "            else:\n",
    "                try:\n",
    "                    weather_list.append(v[x,y])\n",
    "                except IndexError:\n",
    "                    return None\n",
    "    \n",
    "    return weather_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Dataset for CNN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, matrix_dim, data_len, side):\n",
    "    '''\n",
    "    Supplement the list produced in `create_labeled_data` with data where there was no data\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - data_len: how many \"no-fire\" pixel-matrix pairs we want to return\n",
    "        - side: half the length of the dimension of the outpur matrix\n",
    "    Returns:\n",
    "        - no_fire: a list of sets, where the second value (0, 1) represents whether fire is present for a given \n",
    "        pixel, and the first value is a matrix centered on the second value for the previous day and represents \n",
    "        where the fire was on the previous day\n",
    "    '''\n",
    "        \n",
    "    no_fire = []\n",
    "    vals = []\n",
    "    \n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 0)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "    vals = random.sample(vals, 2*data_len)\n",
    "    \n",
    "    for (xi, yi) in vals:\n",
    "        xi_r = xi + side\n",
    "        xi_l = xi - side\n",
    "        yi_b = yi + side\n",
    "        yi_t = yi - side\n",
    "\n",
    "        m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "\n",
    "        # control for edge cases where shape doesn't match up - not sure why this is happening\n",
    "        if m.shape == (matrix_dim, matrix_dim):\n",
    "            weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "            if weather_data is not None:\n",
    "                no_fire.append(((weather_data, m), 0))\n",
    "    \n",
    "    len_no_fire = len(no_fire)\n",
    "    \n",
    "    num_pixels = min(len_no_fire, data_len)\n",
    "    no_fire = random.sample(no_fire, data_len)\n",
    "    \n",
    "    return no_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_data(dataset, matrix_dim, labeled_multiplier):\n",
    "    '''\n",
    "    Create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    whether there was fire in the center pixel on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - labeled_multiplier: a hyperparameter for how much \"no-fire\" labeled data to add to the training set\n",
    "    Returns:\n",
    "        - data: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, \n",
    "        and the first value is a matrix centered on the second value for the previous day and represents where the \n",
    "        fire was on the previous day\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 1)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "                        \n",
    "            weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "            \n",
    "            if weather_data is not None:\n",
    "                data.append(((weather_data, m), 1))\n",
    "    \n",
    "    data_len = len(data)*labeled_multiplier\n",
    "    \n",
    "    # balance this dataset with values where there is no fire\n",
    "    print('Balance dataset')\n",
    "    no_fire = balance_dataset(dataset, matrix_dim, data_len, side)\n",
    "    \n",
    "    # combine and shuffle\n",
    "    data += no_fire    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_for_cnn(data, matrix_dim):\n",
    "    '''\n",
    "    Takes a list of ((weather_data, fire_data), integer) pairs and returns fire data, weather data, and output labels.\n",
    "    \n",
    "    Args:\n",
    "        - data: a list of (matrix, integer) pairs\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - fire: array of input data in matrix_dim X matrix_dim shape\n",
    "        - weather: list of normalized weather weights\n",
    "        - Y: array of output labels (0 or 1)\n",
    "    '''\n",
    "    \n",
    "    fire = []\n",
    "    weather = []\n",
    "    Y = []\n",
    "\n",
    "    for ((w, f), y) in data:\n",
    "        f = np.asarray(f)\n",
    "        fire.append(f)\n",
    "        \n",
    "        w = np.asarray(w)\n",
    "        weather.append(w)\n",
    "        \n",
    "        Y.append(y)\n",
    "\n",
    "    fire = np.asarray(fire)\n",
    "    weather = np.asarray(weather)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    obs = len(fire)\n",
    "    \n",
    "    fire = fire.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "    return fire, weather, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_s3(s3_client, array, bucket_name, key_name):\n",
    "    '''\n",
    "    Uploads pre-processed data to S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - array: numpy array to save to s3\n",
    "        - bucket_name: name of bucket on s3 to save array to\n",
    "        - key_name: directory/file_name to save data to\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    pickle.dump(array, array_data)\n",
    "    array_data.seek(0)\n",
    "    \n",
    "    s3_client.upload_fileobj(array_data, bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Starting data preprocessing for year:  2014\n",
      "2020-04-11 18:20:51.699309\n",
      "*****************************************\n",
      "Balance dataset\n",
      "Fire data shape:  (45475, 32, 32, 1)\n",
      "Weather data shape:  (45475, 8)\n",
      "Y data shape:  (45475,)\n",
      "Save fire data to s3\n",
      "Save weather data to s3\n",
      "Save labels to S3\n",
      "Time:  0:02:10.815958\n"
     ]
    }
   ],
   "source": [
    "# run the datat preprocessing pipeline\n",
    "\n",
    "# years = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "years = [2014]\n",
    "\n",
    "for y in years:\n",
    "    print('*****************************************')\n",
    "    print('Starting data preprocessing for year: ', y)\n",
    "    time = dt.now()\n",
    "    print (time)\n",
    "    print('*****************************************')\n",
    "    \n",
    "    # pull data from s3\n",
    "    pull_fire_data_from_s3(y, tif_directory)\n",
    "    pull_weather_data_from_s3(y, weather_directory)\n",
    "\n",
    "    # get fire speed data\n",
    "    fire_speed_data_dict = process_fire_data_png(tif_directory, speed_file)\n",
    "\n",
    "    # get fire direction data\n",
    "    fire_dir_data_dict = process_fire_data_tiff(tif_directory, direction_file)\n",
    "\n",
    "    # combine fire speed and fire direction datasets\n",
    "    fire_data_dict = combine_dicts(fire_speed_data_dict, fire_dir_data_dict)\n",
    "\n",
    "    # create weather dict and combine with fire speed and fire direction\n",
    "    weather_data, max_values = create_weather_dict(weather_directory, normalized_weather, weather_vars, fire_data_dict)\n",
    "    \n",
    "    # return matrices of which pixels belong to which fire and which day of the year the pixel was on fire\n",
    "    fire_data_dict, fireline = data_processing(tif_directory)\n",
    "\n",
    "    # create matrices for each fire_id that show were the fire was on a given day during the year \n",
    "    fire_data_dict = create_one_hot_matrices(fire_data_dict, fireline)\n",
    "\n",
    "    # create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    # the fire was on the following day\n",
    "    small_dataset = create_day_pairs(fire_data_dict)\n",
    "\n",
    "    # create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    # whether there was fire in the center pixel on the following day\n",
    "    data = create_labeled_data(small_dataset, matrix_dim, labeled_multiplier)\n",
    "\n",
    "    # takes data pairs and returns fire data, weather data, and output labels\n",
    "    fire, weather, Y = prep_dataset_for_cnn(data, matrix_dim)\n",
    "    print('Fire data shape: ', fire.shape)\n",
    "    print('Weather data shape: ', weather.shape)\n",
    "    print('Y data shape: ', Y.shape)\n",
    "    \n",
    "    # save fire data to S3\n",
    "    print('Save fire data to s3')\n",
    "    fire_name = 'input_fire/fire_{}.pickle'.format(y)\n",
    "    save_array_to_s3(s3_client, fire, bucket_name, fire_name)\n",
    "    \n",
    "    # save weather data to S3\n",
    "    print('Save weather data to s3')\n",
    "    weather_name = 'input_weather/weather_{}.pickle'.format(y)\n",
    "    save_array_to_s3(s3_client, weather, bucket_name, weather_name)\n",
    "\n",
    "    #save label data to S3\n",
    "    print('Save labels to S3')\n",
    "    label_name = 'labels/label_{}.pickle'.format(y)\n",
    "    save_array_to_s3(s3_client, Y, bucket_name, label_name)\n",
    "    \n",
    "    print('Time: ', (dt.now() - time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
