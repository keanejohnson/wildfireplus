{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# name of directory with tif files\n",
    "directory = \"toydata\"\n",
    "\n",
    "#####################\n",
    "## HYPERPARAMETERS ##\n",
    "#####################\n",
    "\n",
    "# the desired height and width of the matrix to feed into the CNN\n",
    "matrix_dim = 32\n",
    "\n",
    "# multiplier for amount of zero-labeled data we want to add to dataset\n",
    "labeled_multiplier = 10\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(directory):\n",
    "    '''\n",
    "    Process the dataset in the supplied directory and return matrices of which pixels belong to which fire and \n",
    "    which day of the year the pixel was on fire.\n",
    "    \n",
    "    Args: \n",
    "        - directory: name of directory with tif files\n",
    "    Returns: \n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "\n",
    "    # convert to np array\n",
    "    fire_id = Image.open(tiff_dict['fireid'])\n",
    "    fire_id = np.array(fire_id)\n",
    "    fire_id[fire_id == -9999] = 0\n",
    "\n",
    "    fireline = Image.open(tiff_dict['Global_fire_atlas_firelinecrop'])\n",
    "    fireline = np.array(fireline)\n",
    "    fireline[fireline == -9999] = 0\n",
    "\n",
    "    # get list of unique fire_ids\n",
    "    fire_ids = set()\n",
    "\n",
    "    for row in fire_id:\n",
    "        for val in row:\n",
    "            fire_ids.add(val)\n",
    "\n",
    "    # remove 0 from fire_ids set because it does not denote a fire\n",
    "    fire_ids.remove(0)\n",
    "\n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        id = str(id)\n",
    "        fire_data_dict[id] = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        indices = np.where(fire_id == id, 1, 0)\n",
    "        fire_data_dict[str(id)] = indices\n",
    "        \n",
    "    return fire_data_dict, fireline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_matrices(data_dict, fireline):\n",
    "    '''\n",
    "    Create matrices for each fire_id that show were the fire was on a given day during the year.\n",
    "    \n",
    "    Args:\n",
    "        - data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    '''\n",
    "    \n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for key, val in data_dict.items():\n",
    "        data = {}\n",
    "                \n",
    "        for y in range(1, 366):\n",
    "            mask = ((fireline == y) & (val == 1))\n",
    "            mask = mask.astype(int)\n",
    "        \n",
    "            if np.sum(mask) > 0:\n",
    "                data[str(y)] = mask\n",
    "        \n",
    "        fire_data_dict[key] = data\n",
    "        \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_pairs(fire_data_dict):\n",
    "    '''\n",
    "    Create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    the fire was on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    Returns:\n",
    "        - train_labels: a list of sets where the first value of the set is a one-hot encoded 2D array of fire \n",
    "        spread on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2:\n",
    "        [\n",
    "            (one-hot encoded 2D array of fire spread on that day_1, one-hot encoded 2D array of fire spread on day_2),\n",
    "            (one-hot encoded 2D array of fire spread on that day_2, one-hot encoded 2D array of fire spread on day_3),\n",
    "        ]\n",
    "    '''\n",
    "    \n",
    "    train_labels = []\n",
    "\n",
    "    for key, value in fire_data_dict.items():\n",
    "        burn_matrices = list(value.values())\n",
    "        \n",
    "        for index, day in enumerate(burn_matrices):\n",
    "\n",
    "            if index < len(burn_matrices) - 1:\n",
    "                day_1 = burn_matrices[index]\n",
    "                day_2_index = index + 1\n",
    "                day_2 = burn_matrices[day_2_index]\n",
    "                \n",
    "                pair = (day_1, day_2)\n",
    "                train_labels.append(pair)\n",
    "\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_data(dataset, matrix_dim):\n",
    "    '''\n",
    "    Create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    whether there was fire in the center pixel on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - data: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, and the\n",
    "        first value is a matrix centered on the second value for the previous day and represents where the fire was\n",
    "        on the previous day\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (x, y) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 1)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "\n",
    "            data.append((m, 1))\n",
    "    \n",
    "    data_len = len(data)\n",
    "    num_pixels = min(int(data_len*labeled_multiplier), data_len)\n",
    "    \n",
    "    # balance this dataset with values where there is no fire\n",
    "    no_fire = balance_dataset(dataset, matrix_dim, num_pixels, side)\n",
    "    \n",
    "    # combine and shuffle\n",
    "    data += no_fire    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, matrix_dim, num_pixels, side):\n",
    "    '''\n",
    "    Supplement the list produced in `create_labeled_data` with data where there was no data\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - num_pixels: how many \"no-fire\" pixel-matrix pairs we want to return\n",
    "        - side: half the length of the dimension of the outpur matrix\n",
    "    Returns:\n",
    "        - no_fire: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, and the\n",
    "        first value is a matrix centered on the second value for the previous day and represents where the fire was\n",
    "        on the previous day\n",
    "    '''\n",
    "        \n",
    "    no_fire = []\n",
    "\n",
    "    for (x, y) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 0)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "            \n",
    "            # control for edge cases where shape doesn't match up - not sure why this is happening\n",
    "            if m.shape == (32, 32):\n",
    "                no_fire.append((m, 0))\n",
    "    \n",
    "    no_fire = random.sample(no_fire, num_pixels)\n",
    "    \n",
    "    return no_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_for_cnn(data):\n",
    "    '''\n",
    "    Takes a list of (matrix, integer) pairs and returns input data and output labels split into train and test sets\n",
    "    \n",
    "    Args:\n",
    "        - data: a list of (matrix, integer) pairs\n",
    "    Returns:\n",
    "        - X_train: array of input data in matrix_dim X matrix_dim shape\n",
    "        - X_test: array of input data in matrix_dim X matrix_dim shape\n",
    "        - Y_train: array of output labels (0 or 1)\n",
    "        - Y_test: array of output labels (0 or 1)\n",
    "    '''\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for (x, y) in data:\n",
    "        x = np.asarray(x)\n",
    "        X.append(x)\n",
    "        \n",
    "        Y.append(y)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    obs = len(X)\n",
    "    \n",
    "    X = X.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data_dict, fireline = data_processing(directory)\n",
    "fire_data_dict = create_one_hot_matrices(fire_data_dict, fireline)\n",
    "small_dataset = create_day_pairs(fire_data_dict)\n",
    "data = create_labeled_data(small_dataset, matrix_dim)\n",
    "X, Y = prep_dataset_for_cnn(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Fire Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1: fire image data with Sequential API\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model_1.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Conv2D(64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Flatten())\n",
    "\n",
    "# Final dense layer \n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_1.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 2s 382us/step - loss: 0.7010 - accuracy: 0.5188 - f1_score: 0.4408 - auc_34: 0.5035 - val_loss: 0.6963 - val_accuracy: 0.4922 - val_f1_score: 0.0000e+00 - val_auc_34: 0.5225\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 2s 345us/step - loss: 0.6100 - accuracy: 0.6615 - f1_score: 0.6168 - auc_34: 0.5571 - val_loss: 0.4264 - val_accuracy: 0.9860 - val_f1_score: 0.9859 - val_auc_34: 0.6425\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 2s 318us/step - loss: 0.2920 - accuracy: 0.8935 - f1_score: 0.8793 - auc_34: 0.7232 - val_loss: 0.2091 - val_accuracy: 0.9172 - val_f1_score: 0.9114 - val_auc_34: 0.7902\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 2s 332us/step - loss: 0.1843 - accuracy: 0.9403 - f1_score: 0.9329 - auc_34: 0.8322 - val_loss: 0.1664 - val_accuracy: 0.9401 - val_f1_score: 0.9380 - val_auc_34: 0.8633\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 2s 324us/step - loss: 0.1509 - accuracy: 0.9534 - f1_score: 0.9432 - auc_34: 0.8847 - val_loss: 0.2758 - val_accuracy: 0.9897 - val_f1_score: 0.9895 - val_auc_34: 0.9011\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 2s 323us/step - loss: 0.1335 - accuracy: 0.9554 - f1_score: 0.9546 - auc_34: 0.9126 - val_loss: 0.1304 - val_accuracy: 0.9542 - val_f1_score: 0.9527 - val_auc_34: 0.9233\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 2s 320us/step - loss: 0.1110 - accuracy: 0.9667 - f1_score: 0.9638 - auc_34: 0.9316 - val_loss: 0.1237 - val_accuracy: 0.9727 - val_f1_score: 0.9724 - val_auc_34: 0.9386\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 2s 314us/step - loss: 0.0941 - accuracy: 0.9721 - f1_score: 0.9702 - auc_34: 0.9443 - val_loss: 0.1710 - val_accuracy: 0.9904 - val_f1_score: 0.9905 - val_auc_34: 0.9494\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 2s 313us/step - loss: 0.0848 - accuracy: 0.9756 - f1_score: 0.9737 - auc_34: 0.9536 - val_loss: 0.1066 - val_accuracy: 0.9741 - val_f1_score: 0.9739 - val_auc_34: 0.9574\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 2s 328us/step - loss: 0.0788 - accuracy: 0.9776 - f1_score: 0.9771 - auc_34: 0.9606 - val_loss: 0.1101 - val_accuracy: 0.9704 - val_f1_score: 0.9700 - val_auc_34: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe7e1063d90>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_1.fit(\n",
    "    x = [X], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.9731664 ],\n",
       "       [0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.01924348],\n",
       "       [0.01924348]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Fire Image Data and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data and weather data with functional API\n",
    "\n",
    "# Define inputs shape\n",
    "image_shape = X[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "weather_inputs = Input()\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "output_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "output_2 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(output_1)\n",
    "output_3 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(output_2)\n",
    "output_4 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(output_3)\n",
    "output_5 = Dropout(0.2)(output_4)\n",
    "output_6 = Flatten()(output_5)\n",
    "\n",
    "# Add layer for weather data\n",
    "output_7 = \n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(output_7)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 2s 393us/step - loss: 0.7019 - accuracy: 0.5143 - f1_score: 0.4211 - auc_32: 0.5116 - val_loss: 0.6998 - val_accuracy: 0.5078 - val_f1_score: 0.6699 - val_auc_32: 0.5256\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 2s 330us/step - loss: 0.6378 - accuracy: 0.6229 - f1_score: 0.5822 - auc_32: 0.5494 - val_loss: 0.4380 - val_accuracy: 0.9305 - val_f1_score: 0.9266 - val_auc_32: 0.6366\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 2s 330us/step - loss: 0.2917 - accuracy: 0.9040 - f1_score: 0.8912 - auc_32: 0.7293 - val_loss: 0.2099 - val_accuracy: 0.9268 - val_f1_score: 0.9223 - val_auc_32: 0.7952\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 2s 314us/step - loss: 0.1800 - accuracy: 0.9414 - f1_score: 0.9291 - auc_32: 0.8361 - val_loss: 0.1841 - val_accuracy: 0.9231 - val_f1_score: 0.9179 - val_auc_32: 0.8660\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 2s 321us/step - loss: 0.1441 - accuracy: 0.9514 - f1_score: 0.9477 - auc_32: 0.8863 - val_loss: 0.1708 - val_accuracy: 0.9756 - val_f1_score: 0.9754 - val_auc_32: 0.9030\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 2s 342us/step - loss: 0.1154 - accuracy: 0.9651 - f1_score: 0.9627 - auc_32: 0.9159 - val_loss: 0.1532 - val_accuracy: 0.9475 - val_f1_score: 0.9461 - val_auc_32: 0.9261\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 2s 343us/step - loss: 0.1156 - accuracy: 0.9654 - f1_score: 0.9570 - auc_32: 0.9334 - val_loss: 0.1395 - val_accuracy: 0.9527 - val_f1_score: 0.9512 - val_auc_32: 0.9399\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 2s 326us/step - loss: 0.0907 - accuracy: 0.9728 - f1_score: 0.9655 - auc_32: 0.9454 - val_loss: 0.1176 - val_accuracy: 0.9534 - val_f1_score: 0.9522 - val_auc_32: 0.9504\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 2s 326us/step - loss: 0.0830 - accuracy: 0.9760 - f1_score: 0.9685 - auc_32: 0.9545 - val_loss: 0.1024 - val_accuracy: 0.9749 - val_f1_score: 0.9747 - val_auc_32: 0.9582\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 2s 330us/step - loss: 0.0738 - accuracy: 0.9791 - f1_score: 0.9723 - auc_32: 0.9614 - val_loss: 0.1006 - val_accuracy: 0.9734 - val_f1_score: 0.9732 - val_auc_32: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe6e629dcd0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [X], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
