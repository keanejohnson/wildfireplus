{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# name of directory with fire tif files\n",
    "tif_directory = \"toydata\"\n",
    "\n",
    "#####################\n",
    "## HYPERPARAMETERS ##\n",
    "#####################\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# multiplier for amount of zero-labeled data we want to add to dataset\n",
    "labeled_multiplier = 2\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(directory):\n",
    "    '''\n",
    "    Process the dataset in the supplied directory and return matrices of which pixels belong to which fire and \n",
    "    which day of the year the pixel was on fire.\n",
    "    \n",
    "    Args: \n",
    "        - directory: name of directory with tif files\n",
    "    Returns: \n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "\n",
    "    # convert to np array\n",
    "    fire_id = Image.open(tiff_dict['fireid'])\n",
    "    fire_id = np.array(fire_id)\n",
    "    fire_id[fire_id == -9999] = 0\n",
    "\n",
    "    fireline = Image.open(tiff_dict['Global_fire_atlas_firelinecrop'])\n",
    "    fireline = np.array(fireline)\n",
    "    fireline[fireline == -9999] = 0\n",
    "\n",
    "    # get list of unique fire_ids\n",
    "    fire_ids = set()\n",
    "\n",
    "    for row in fire_id:\n",
    "        for val in row:\n",
    "            fire_ids.add(val)\n",
    "\n",
    "    # remove 0 from fire_ids set because it does not denote a fire\n",
    "    fire_ids.remove(0)\n",
    "\n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        id = str(id)\n",
    "        fire_data_dict[id] = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        indices = np.where(fire_id == id, 1, 0)\n",
    "        fire_data_dict[str(id)] = indices\n",
    "        \n",
    "    return fire_data_dict, fireline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_matrices(data_dict, fireline):\n",
    "    '''\n",
    "    Create matrices for each fire_id that show were the fire was on a given day during the year.\n",
    "    \n",
    "    Args:\n",
    "        - data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    '''\n",
    "    \n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for key, val in data_dict.items():\n",
    "        data = {}\n",
    "                \n",
    "        for y in range(1, 366):\n",
    "            mask = ((fireline == y) & (val == 1))\n",
    "            mask = mask.astype(int)\n",
    "        \n",
    "            if np.sum(mask) > 0:\n",
    "                data[str(y)] = mask\n",
    "        \n",
    "        fire_data_dict[key] = data\n",
    "        \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_pairs(fire_data_dict):\n",
    "    '''\n",
    "    Create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    the fire was on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    Returns:\n",
    "        - train_labels: a list of sets where the first value of the set is a one-hot encoded 2D array of fire \n",
    "        spread on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2:\n",
    "        [\n",
    "            (one-hot encoded 2D array of fire spread on that day_1, one-hot encoded 2D array of fire spread on day_2),\n",
    "            (one-hot encoded 2D array of fire spread on that day_2, one-hot encoded 2D array of fire spread on day_3),\n",
    "        ]\n",
    "    '''\n",
    "    \n",
    "    train_labels = []\n",
    "\n",
    "    for key, value in fire_data_dict.items():\n",
    "        burn_matrices = list(value.values())\n",
    "        \n",
    "        for index, day in enumerate(burn_matrices):\n",
    "\n",
    "            if index < len(burn_matrices) - 1:\n",
    "                day_1 = burn_matrices[index]\n",
    "                day_2_index = index + 1\n",
    "                day_2 = burn_matrices[day_2_index]\n",
    "                \n",
    "                pair = (day_1, day_2)\n",
    "                train_labels.append(pair)\n",
    "\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, matrix_dim, num_pixels, side):\n",
    "    '''\n",
    "    Supplement the list produced in `create_labeled_data` with data where there was no data\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - num_pixels: how many \"no-fire\" pixel-matrix pairs we want to return\n",
    "        - side: half the length of the dimension of the outpur matrix\n",
    "    Returns:\n",
    "        - no_fire: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, and the\n",
    "        first value is a matrix centered on the second value for the previous day and represents where the fire was\n",
    "        on the previous day\n",
    "    '''\n",
    "        \n",
    "    no_fire = []\n",
    "\n",
    "    for (x, y) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 0)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "            \n",
    "            # control for edge cases where shape doesn't match up - not sure why this is happening\n",
    "            if m.shape == (matrix_dim, matrix_dim):\n",
    "                no_fire.append((m, 0))\n",
    "    \n",
    "    no_fire = random.sample(no_fire, num_pixels)\n",
    "    \n",
    "    return no_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_data(dataset, matrix_dim):\n",
    "    '''\n",
    "    Create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    whether there was fire in the center pixel on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - data: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, and the\n",
    "        first value is a matrix centered on the second value for the previous day and represents where the fire was\n",
    "        on the previous day\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (x, y) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 1)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "\n",
    "            data.append((m, 1))\n",
    "    \n",
    "    data_len = len(data)\n",
    "    num_pixels = min(int(data_len*labeled_multiplier), data_len)\n",
    "    \n",
    "    # balance this dataset with values where there is no fire\n",
    "    no_fire = balance_dataset(dataset, matrix_dim, num_pixels, side)\n",
    "    \n",
    "    # combine and shuffle\n",
    "    data += no_fire    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_for_cnn(data):\n",
    "    '''\n",
    "    Takes a list of (matrix, integer) pairs and returns input data and output labels split into train and test sets\n",
    "    \n",
    "    Args:\n",
    "        - data: a list of (matrix, integer) pairs\n",
    "    Returns:\n",
    "        - X: array of input data in matrix_dim X matrix_dim shape\n",
    "        - Y: array of output labels (0 or 1)\n",
    "    '''\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for (x, y) in data:\n",
    "        x = np.asarray(x)\n",
    "        X.append(x)\n",
    "        \n",
    "        Y.append(y)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    obs = len(X)\n",
    "    \n",
    "    X = X.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data_dict, fireline = data_processing(tif_directory)\n",
    "fire_data_dict = create_one_hot_matrices(fire_data_dict, fireline)\n",
    "small_dataset = create_day_pairs(fire_data_dict)\n",
    "data = create_labeled_data(small_dataset, matrix_dim)\n",
    "X, Y = prep_dataset_for_cnn(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Fire Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1: fire image data with Sequential API\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model_1.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Conv2D(64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Flatten())\n",
    "\n",
    "# Final dense layer \n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_1.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 2s 403us/step - loss: 0.7091 - accuracy: 0.4981 - f1_score: 0.4381 - auc_51: 0.4868 - val_loss: 0.6902 - val_accuracy: 0.5026 - val_f1_score: 0.0000e+00 - val_auc_51: 0.5037\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 2s 283us/step - loss: 0.6796 - accuracy: 0.5535 - f1_score: 0.4909 - auc_51: 0.5193 - val_loss: 0.6051 - val_accuracy: 0.7191 - val_f1_score: 0.5951 - val_auc_51: 0.5600\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 2s 341us/step - loss: 0.3951 - accuracy: 0.8571 - f1_score: 0.8270 - auc_51: 0.6519 - val_loss: 0.3700 - val_accuracy: 0.8337 - val_f1_score: 0.7881 - val_auc_51: 0.7284\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 2s 375us/step - loss: 0.2191 - accuracy: 0.9309 - f1_score: 0.9171 - auc_51: 0.7793 - val_loss: 0.1796 - val_accuracy: 0.9209 - val_f1_score: 0.9111 - val_auc_51: 0.8211\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 2s 315us/step - loss: 0.1771 - accuracy: 0.9429 - f1_score: 0.9321 - auc_51: 0.8487 - val_loss: 0.1367 - val_accuracy: 0.9571 - val_f1_score: 0.9544 - val_auc_51: 0.8718\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 2s 299us/step - loss: 0.1450 - accuracy: 0.9577 - f1_score: 0.9481 - auc_51: 0.8891 - val_loss: 0.1338 - val_accuracy: 0.9438 - val_f1_score: 0.9396 - val_auc_51: 0.9028\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 2s 293us/step - loss: 0.1310 - accuracy: 0.9630 - f1_score: 0.9548 - auc_51: 0.9135 - val_loss: 0.1011 - val_accuracy: 0.9564 - val_f1_score: 0.9534 - val_auc_51: 0.9229\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 2s 284us/step - loss: 0.1252 - accuracy: 0.9643 - f1_score: 0.9564 - auc_51: 0.9299 - val_loss: 0.0944 - val_accuracy: 0.9571 - val_f1_score: 0.9541 - val_auc_51: 0.9365\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 2s 282us/step - loss: 0.1068 - accuracy: 0.9708 - f1_score: 0.9637 - auc_51: 0.9420 - val_loss: 0.0795 - val_accuracy: 0.9793 - val_f1_score: 0.9775 - val_auc_51: 0.9469\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 2s 281us/step - loss: 0.1042 - accuracy: 0.9745 - f1_score: 0.9672 - auc_51: 0.9511 - val_loss: 0.0849 - val_accuracy: 0.9630 - val_f1_score: 0.9605 - val_auc_51: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe6c18ee850>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_1.fit(\n",
    "    x = X, \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5093185 ],\n",
       "       [0.9998543 ],\n",
       "       [1.        ],\n",
       "       [0.02128283],\n",
       "       [0.02128283],\n",
       "       [0.02128283],\n",
       "       [0.02128283],\n",
       "       [0.99996305],\n",
       "       [0.02128283],\n",
       "       [0.02128283]], dtype=float32)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.predict(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Fire Image Data and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data and weather data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = X[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "output_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "output_2 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(output_1)\n",
    "output_3 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(output_2)\n",
    "output_4 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(output_3)\n",
    "output_5 = Dropout(0.2)(output_4)\n",
    "output_6 = Flatten()(output_5)\n",
    "\n",
    "# Add layers for weather interpretation\n",
    "\n",
    "\n",
    "# Combine the layers\n",
    "\n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(output_6)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=image_inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 2s 326us/step - loss: 0.7014 - accuracy: 0.5178 - f1_score: 0.4760 - auc_48: 0.5149 - val_loss: 0.6910 - val_accuracy: 0.5041 - val_f1_score: 0.0000e+00 - val_auc_48: 0.5264\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 1s 263us/step - loss: 0.6560 - accuracy: 0.6064 - f1_score: 0.6168 - auc_48: 0.5492 - val_loss: 0.5034 - val_accuracy: 0.8721 - val_f1_score: 0.8446 - val_auc_48: 0.6185\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 1s 262us/step - loss: 0.3353 - accuracy: 0.8769 - f1_score: 0.8647 - auc_48: 0.7048 - val_loss: 0.2030 - val_accuracy: 0.9527 - val_f1_score: 0.9488 - val_auc_48: 0.7777\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 1s 261us/step - loss: 0.1969 - accuracy: 0.9338 - f1_score: 0.9279 - auc_48: 0.8218 - val_loss: 0.1456 - val_accuracy: 0.9616 - val_f1_score: 0.9586 - val_auc_48: 0.8558\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 1s 262us/step - loss: 0.1441 - accuracy: 0.9508 - f1_score: 0.9408 - auc_48: 0.8793 - val_loss: 0.2493 - val_accuracy: 0.9919 - val_f1_score: 0.9916 - val_auc_48: 0.8973\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 1s 263us/step - loss: 0.1755 - accuracy: 0.9408 - f1_score: 0.9395 - auc_48: 0.9071 - val_loss: 0.1133 - val_accuracy: 0.9667 - val_f1_score: 0.9641 - val_auc_48: 0.9181\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 1s 268us/step - loss: 0.1076 - accuracy: 0.9645 - f1_score: 0.9564 - auc_48: 0.9272 - val_loss: 0.0990 - val_accuracy: 0.9675 - val_f1_score: 0.9650 - val_auc_48: 0.9349\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 1s 263us/step - loss: 0.0965 - accuracy: 0.9695 - f1_score: 0.9672 - auc_48: 0.9411 - val_loss: 0.1046 - val_accuracy: 0.9667 - val_f1_score: 0.9640 - val_auc_48: 0.9465\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 1s 265us/step - loss: 0.0862 - accuracy: 0.9747 - f1_score: 0.9680 - auc_48: 0.9510 - val_loss: 0.0841 - val_accuracy: 0.9808 - val_f1_score: 0.9792 - val_auc_48: 0.9551\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 1s 266us/step - loss: 0.0833 - accuracy: 0.9765 - f1_score: 0.9752 - auc_48: 0.9584 - val_loss: 0.0812 - val_accuracy: 0.9867 - val_f1_score: 0.9864 - val_auc_48: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe980de2c10>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [X], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
