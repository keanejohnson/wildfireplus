{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model - Predictions with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import csv\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import rasterio as rio\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# name of directory with fire tif files\n",
    "tif_directory = \"toydata\"\n",
    "\n",
    "# name of directory with weather data\n",
    "weather_directory = 'weather_data'\n",
    "\n",
    "# name of fire direction file\n",
    "direction_file = 'Global_fire_atlas_dircrop'\n",
    "\n",
    "# name of fire speed file\n",
    "speed_file = 'Global_fire_atlas_speedcrop'\n",
    "\n",
    "# weather and fire data to include in model\n",
    "rainint = True\n",
    "raintot = False\n",
    "high_t = True\n",
    "low_t = True\n",
    "humidity = True\n",
    "wind_speed = True\n",
    "wind_direction = True\n",
    "cloud_cover = False\n",
    "fire_direction = True\n",
    "fire_speed = True\n",
    "\n",
    "weather_variables = {\n",
    "    'rainint': rainint, \n",
    "    'raintot': raintot, \n",
    "    'High T': high_t, \n",
    "    'Low T': low_t, \n",
    "    'Humidity': humidity, \n",
    "    'Wind Speed': wind_speed, \n",
    "    'Wind Direction': wind_direction, \n",
    "    'Cloud Cover': cloud_cover,\n",
    "    'Fire Direction': fire_direction,\n",
    "    'Fire Speed': fire_speed\n",
    "}\n",
    "\n",
    "weather_vars = []\n",
    "\n",
    "for k, v in weather_variables.items():\n",
    "    if v == True:\n",
    "        weather_vars.append(k)\n",
    "\n",
    "#####################\n",
    "## HYPERPARAMETERS ##\n",
    "#####################\n",
    "\n",
    "# scale the weather data - yea or nay\n",
    "normalized_weather = True\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# multiplier for amount of zero-labeled data we want to add to dataset\n",
    "labeled_multiplier = 4\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Dataset Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(directory):\n",
    "    '''\n",
    "    Process the dataset in the supplied directory and return matrices of which pixels belong to which fire and \n",
    "    which day of the year the pixel was on fire.\n",
    "    \n",
    "    Args: \n",
    "        - directory: name of directory with tif files\n",
    "    Returns: \n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "\n",
    "    # convert to np array\n",
    "    fire_id = Image.open(tiff_dict['fireid'])\n",
    "    fire_id = np.array(fire_id)\n",
    "    fire_id[fire_id == -9999] = 0\n",
    "\n",
    "    fireline = Image.open(tiff_dict['Global_fire_atlas_firelinecrop'])\n",
    "    fireline = np.array(fireline)\n",
    "    fireline[fireline == -9999] = 0\n",
    "\n",
    "    # get list of unique fire_ids\n",
    "    fire_ids = set()\n",
    "\n",
    "    for row in fire_id:\n",
    "        for val in row:\n",
    "            fire_ids.add(val)\n",
    "\n",
    "    # remove 0 from fire_ids set because it does not denote a fire\n",
    "    fire_ids.remove(0)\n",
    "\n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        id = str(id)\n",
    "        fire_data_dict[id] = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        indices = np.where(fire_id == id, 1, 0)\n",
    "        fire_data_dict[str(id)] = indices\n",
    "        \n",
    "    return fire_data_dict, fireline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_matrices(data_dict, fireline):\n",
    "    '''\n",
    "    Create matrices for each fire_id that show were the fire was on a given day during the year.\n",
    "    \n",
    "    Args:\n",
    "        - data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    '''\n",
    "    \n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for key, val in data_dict.items():\n",
    "        data = {}\n",
    "                \n",
    "        for y in range(1, 366):\n",
    "            mask = ((fireline == y) & (val == 1))\n",
    "            mask = mask.astype(int)\n",
    "        \n",
    "            if np.sum(mask) > 0:\n",
    "                data[str(y)] = mask\n",
    "        \n",
    "        fire_data_dict[key] = data\n",
    "        \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_pairs(fire_data_dict):\n",
    "    '''\n",
    "    Create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    the fire was on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    Returns:\n",
    "        - train_labels: a list of sets where the first value of the set is a one-hot encoded 2D array of fire \n",
    "        spread on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2:\n",
    "        [\n",
    "            (one-hot encoded 2D array of fire spread on that day_1, one-hot encoded 2D array of fire spread on day_2),\n",
    "            (one-hot encoded 2D array of fire spread on that day_2, one-hot encoded 2D array of fire spread on day_3),\n",
    "        ]\n",
    "    '''\n",
    "    \n",
    "    train_labels = []\n",
    "\n",
    "    for key, value in fire_data_dict.items():\n",
    "        burn_matrices = list(value.values())\n",
    "        day_of_year = list(value.keys())\n",
    "        \n",
    "        for index, day in enumerate(burn_matrices):\n",
    "\n",
    "            if index < len(burn_matrices) - 1:\n",
    "                day_1 = burn_matrices[index]\n",
    "                day_2_index = index + 1\n",
    "                day_2 = burn_matrices[day_2_index]\n",
    "                \n",
    "                doy = day_of_year[day_2_index]\n",
    "                \n",
    "                pair = (day_1, day_2)\n",
    "                train_labels.append((doy, pair))\n",
    "\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_tiff(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied tiff file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that tiff file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of tiff file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['Global_fire_atlas_dobcrop'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert tif of interest to np array\n",
    "    fire_data_mat = Image.open(tiff_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Direction'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_png(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied png file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that png file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of png file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "    png_files = []\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.png'):\n",
    "            png_files.append(path + '/' + f)\n",
    "    \n",
    "    tiff_dict = {}\n",
    "    png_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "    \n",
    "    for f in png_files:\n",
    "        k = f.split('/')[-1].split('.png')[0]\n",
    "        png_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['Global_fire_atlas_dobcrop'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert png of interest to np array\n",
    "    fire_data_mat = Image.open(png_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Speed'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dicts(dict_1, dict_2):\n",
    "    '''\n",
    "    A helper function to combine the values of two dictionaries that have the same keys.\n",
    "    \n",
    "    Args:\n",
    "        - dict_1: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "        - dict_2: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "    Returns:\n",
    "        - dict_2: combined dictionary of dict_1 and dict_2\n",
    "    '''\n",
    "      \n",
    "    for k, v in dict_1.items():\n",
    "        for att, mat in v.items():\n",
    "            dict_2[k][att] = mat\n",
    "            \n",
    "    return dict_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_dict(directory, normalized_weather, weather_vars, fire_data_dict):\n",
    "    '''\n",
    "    Create a dictionary of weather data from a pickled file\n",
    "    Args:\n",
    "        - directory: path to weather pickle file\n",
    "        - normalized_weather: True/False to scale using max value\n",
    "        - weather_vars: list of weather variables to include in model\n",
    "    Returns:\n",
    "        - weather_data: dictionary of key (day of year) and value (dictionary of key (weather parameter) \n",
    "        and value (matrix of value for each pixel))\n",
    "        - max_values: a list of max values for each weather feature to use to normalize data\n",
    "    '''\n",
    "\n",
    "    path = os.path.abspath(directory)\n",
    "    \n",
    "    weather_file = ''\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.pickle'):\n",
    "            weather_file = path + '/' + f\n",
    "    \n",
    "    weather = pd.read_pickle(weather_file)\n",
    "    \n",
    "    weather_dict = {}\n",
    "    \n",
    "    for k, v in weather.items():\n",
    "        weather_dict[k] = {}\n",
    "        \n",
    "        for att, matrix in v.items():\n",
    "            if att in weather_vars:\n",
    "                \n",
    "                # scale to kelvin\n",
    "                if att in ['High T', 'Low T']:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    mat += 273.15\n",
    "                    weather_dict[k][att] = mat\n",
    "                else:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    weather_dict[k][att] = mat\n",
    "     \n",
    "    weather_data = {}\n",
    "\n",
    "    for k, v in weather_dict.items():\n",
    "        doy = dt.strptime(k, \"%Y-%m-%d\").strftime(\"%j\")\n",
    "        weather_data[doy] = v\n",
    "        \n",
    "    # add in fire direction and speed\n",
    "    for k, v in fire_data_dict.items():\n",
    "        for att, mat in v.items():\n",
    "            weather_data[k][att] = mat\n",
    "    \n",
    "    # scale weather data\n",
    "    vals = list(weather_data.values())[0]\n",
    "    weather_atts = list(vals.keys())\n",
    "    max_values = dict.fromkeys(weather_atts, 0)\n",
    "    \n",
    "    if normalized_weather == True:\n",
    "        \n",
    "        for k, v in weather_dict.items():\n",
    "\n",
    "            for weather_att, matrix in v.items():\n",
    "                max_val = matrix.max()\n",
    "                if max_val > max_values[weather_att]:\n",
    "                    max_values[weather_att] = max_val\n",
    "    \n",
    "    return weather_data, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(max_values, normalized_weather, day_of_year, x, y):\n",
    "    '''\n",
    "    Fetch weather data for the relevant day and pixel.\n",
    "    \n",
    "    Args:\n",
    "        - max_values: list of max_values for each weather features\n",
    "        - normalized_weather: whether the weather data should be normalized - true/false\n",
    "        - day_of_year: day of the year (1-365)\n",
    "        - x: x-coordinate of matrix\n",
    "        - y: y-coordinate of matrix\n",
    "    Returns:\n",
    "        - weather_list: an array of relevant weather data for that pixel\n",
    "    '''\n",
    "    \n",
    "    weather_list = []\n",
    "    \n",
    "    day_weather = weather_data.get(day_of_year)\n",
    "\n",
    "    if day_weather is None:\n",
    "        return None\n",
    "    else:\n",
    "        for k, v in day_weather.items():\n",
    "            if normalized_weather == True:\n",
    "                max_val = max_values.get(k, 1)\n",
    "                \n",
    "                try:\n",
    "                    val = v[x,y]\n",
    "                    value = val/max_val\n",
    "                    \n",
    "                    if math.isnan(value):\n",
    "                        weather_list.append(0)\n",
    "                    else:\n",
    "                        weather_list.append(value)\n",
    "                except IndexError:\n",
    "                    return None\n",
    "            else:\n",
    "                try:\n",
    "                    weather_list.append(v[x,y])\n",
    "                except IndexError:\n",
    "                    return None\n",
    "    \n",
    "    return weather_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Dataset for CNN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, matrix_dim, num_pixels, side):\n",
    "    '''\n",
    "    Supplement the list produced in `create_labeled_data` with data where there was no data\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - num_pixels: how many \"no-fire\" pixel-matrix pairs we want to return\n",
    "        - side: half the length of the dimension of the outpur matrix\n",
    "    Returns:\n",
    "        - no_fire: a list of sets, where the second value (0, 1) represents whether fire is present for a given \n",
    "        pixel, and the first value is a matrix centered on the second value for the previous day and represents \n",
    "        where the fire was on the previous day\n",
    "    '''\n",
    "        \n",
    "    no_fire = []\n",
    "\n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 0)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "                                    \n",
    "            # control for edge cases where shape doesn't match up - not sure why this is happening\n",
    "            if m.shape == (matrix_dim, matrix_dim):\n",
    "                weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "                if weather_data is not None:\n",
    "                    no_fire.append(((weather_data, m), 0))\n",
    "    \n",
    "    no_fire = random.sample(no_fire, num_pixels)\n",
    "    \n",
    "    return no_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_data(dataset, matrix_dim, labeled_multiplier):\n",
    "    '''\n",
    "    Create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    whether there was fire in the center pixel on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - labeled_multiplier: a hyperparameter for how much \"no-fire\" labeled data to add to the training set\n",
    "    Returns:\n",
    "        - data: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, \n",
    "        and the first value is a matrix centered on the second value for the previous day and represents where the \n",
    "        fire was on the previous day\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 1)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "                        \n",
    "            weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "            \n",
    "            if weather_data is not None:\n",
    "                data.append(((weather_data, m), 1))\n",
    "    \n",
    "    data_len = len(data)\n",
    "    num_pixels = min(int(data_len*labeled_multiplier), data_len)\n",
    "    \n",
    "    # balance this dataset with values where there is no fire\n",
    "    no_fire = balance_dataset(dataset, matrix_dim, num_pixels, side)\n",
    "    \n",
    "    # combine and shuffle\n",
    "    data += no_fire    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_for_cnn(data, matrix_dim):\n",
    "    '''\n",
    "    Takes a list of ((weather_data, fire_data), integer) pairs and returns fire data, weather data, and output labels.\n",
    "    \n",
    "    Args:\n",
    "        - data: a list of (matrix, integer) pairs\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - fire: array of input data in matrix_dim X matrix_dim shape\n",
    "        - weather: list of normalized weather weights\n",
    "        - Y: array of output labels (0 or 1)\n",
    "    '''\n",
    "    \n",
    "    fire = []\n",
    "    weather = []\n",
    "    Y = []\n",
    "\n",
    "    for ((w, f), y) in data:\n",
    "        f = np.asarray(f)\n",
    "        fire.append(f)\n",
    "        \n",
    "        w = np.asarray(w)\n",
    "        weather.append(w)\n",
    "        \n",
    "        Y.append(y)\n",
    "\n",
    "    fire = np.asarray(fire)\n",
    "    weather = np.asarray(weather)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    obs = len(fire)\n",
    "    \n",
    "    fire = fire.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "    return fire, weather, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run the datat preprocessing pipeline\n",
    "\n",
    "# get fire speed data\n",
    "fire_speed_data_dict = process_fire_data_png(tif_directory, speed_file)\n",
    "\n",
    "# get fire direction data\n",
    "fire_dir_data_dict = process_fire_data_tiff(tif_directory, direction_file)\n",
    "\n",
    "# combine fire speed and fire direction datasets\n",
    "fire_data_dict = combine_dicts(fire_speed_data_dict, fire_dir_data_dict)\n",
    "\n",
    "# create weather dict and combine with fire speed and fire direction\n",
    "weather_data, max_values = create_weather_dict(weather_directory, normalized_weather, weather_vars, fire_data_dict)\n",
    "\n",
    "# return matrices of which pixels belong to which fire and which day of the year the pixel was on fire\n",
    "fire_data_dict, fireline = data_processing(tif_directory)\n",
    "\n",
    "# create matrices for each fire_id that show were the fire was on a given day during the year \n",
    "fire_data_dict = create_one_hot_matrices(fire_data_dict, fireline)\n",
    "\n",
    "# create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "# the fire was on the following day\n",
    "small_dataset = create_day_pairs(fire_data_dict)\n",
    "\n",
    "# create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "# whether there was fire in the center pixel on the following day\n",
    "data = create_labeled_data(small_dataset, matrix_dim, labeled_multiplier)\n",
    "\n",
    "# takes data pairs and returns fire data, weather data, and output labels\n",
    "fire, weather, Y = prep_dataset_for_cnn(data, matrix_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually - taken from https://datascience.stackexchange.com/a/45166\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes recall.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - recall: true positives / actual results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes precision.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - precision: true positives / predicted results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - score: f1 score\n",
    "    '''\n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Fire Image Data and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data, weather data, and fire speed/direction data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = fire[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "weather_shape = weather[0].shape\n",
    "weather_inputs = Input(shape = weather_shape)\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "fire_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "fire_2 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(fire_1)\n",
    "fire_3 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(fire_2)\n",
    "fire_4 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_3)\n",
    "fire_5 = Dropout(0.2)(fire_4)\n",
    "fire_6 = Flatten()(fire_5)\n",
    "fire_7 = Dense(64, activation='sigmoid')(fire_6)\n",
    "\n",
    "# Combine the layers\n",
    "concat = concatenate([fire_7, weather_inputs])\n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=[image_inputs, weather_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 206 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 6s 1ms/step - loss: 0.6986 - accuracy: 0.5269 - f1_score: 0.4062 - auc: 0.5446 - val_loss: 0.6815 - val_accuracy: 0.5477 - val_f1_score: 0.1964 - val_auc: 0.5481: 0.518\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 5s 907us/step - loss: 0.6763 - accuracy: 0.5955 - f1_score: 0.5240 - auc: 0.5672 - val_loss: 0.6654 - val_accuracy: 0.5307 - val_f1_score: 0.6736 - val_auc: 0.5900\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 5s 901us/step - loss: 0.6420 - accuracy: 0.6818 - f1_score: 0.6061 - auc: 0.6135 - val_loss: 0.6001 - val_accuracy: 0.7051 - val_f1_score: 0.5557 - val_auc: 0.6469\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 5s 918us/step - loss: 0.5669 - accuracy: 0.7417 - f1_score: 0.6876 - auc: 0.6721 - val_loss: 0.5095 - val_accuracy: 0.7834 - val_f1_score: 0.7030 - val_auc: 0.6988\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 5s 948us/step - loss: 0.4973 - accuracy: 0.7791 - f1_score: 0.7420 - auc: 0.7196 - val_loss: 0.4771 - val_accuracy: 0.7724 - val_f1_score: 0.6855 - val_auc: 0.7368\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 5s 938us/step - loss: 0.4561 - accuracy: 0.8151 - f1_score: 0.7755 - auc: 0.7515 - val_loss: 0.4231 - val_accuracy: 0.8285 - val_f1_score: 0.7764 - val_auc: 0.7662\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 5s 888us/step - loss: 0.4140 - accuracy: 0.8405 - f1_score: 0.8088 - auc: 0.7788 - val_loss: 0.4148 - val_accuracy: 0.8943 - val_f1_score: 0.8723 - val_auc: 0.7906\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 5s 927us/step - loss: 0.3954 - accuracy: 0.8493 - f1_score: 0.8216 - auc: 0.7999 - val_loss: 0.3731 - val_accuracy: 0.8455 - val_f1_score: 0.8004 - val_auc: 0.8089\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 5s 898us/step - loss: 0.3676 - accuracy: 0.8637 - f1_score: 0.8369 - auc: 0.8170 - val_loss: 0.3892 - val_accuracy: 0.9172 - val_f1_score: 0.9067 - val_auc: 0.8242\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 5s 869us/step - loss: 0.3468 - accuracy: 0.8734 - f1_score: 0.8455 - auc: 0.8307 - val_loss: 0.3502 - val_accuracy: 0.9106 - val_f1_score: 0.8956 - val_auc: 0.8374\n",
      "Wall time: 51.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x236dab4de88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [fire, weather], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, cols = 1, titles = None):\n",
    "    '''\n",
    "    Display a list of images in a single figure with matplotlib. Taken from \n",
    "    https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "    \n",
    "    Args:\n",
    "        - images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "        - cols (Default = 1): Number of columns in figure (number of rows is set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "        - titles: List of titles corresponding to each image. Must have the same length as titles.\n",
    "    '''\n",
    "\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    \n",
    "    n_images = len(images)\n",
    "    \n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        plt.imshow(image, cmap='inferno', interpolation='nearest')\n",
    "        a.set_title(title)\n",
    "    \n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_day(fire_id, doy, model, matrix_dim):\n",
    "    '''\n",
    "    Predicts where fire will be on day \"D + 1\" for a provided fire_id and day of year, using a provided model.\n",
    "    \n",
    "    Args:\n",
    "        - fire_id: ID of fire to be predicted\n",
    "        - doy: Day of year to predict fire for\n",
    "        - model: Model to use for predictions\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - prediction: numpy matrix of predicted fire probabilities\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    fire_id = str(fire_id)\n",
    "    doy = str(doy)\n",
    "    \n",
    "    try:\n",
    "        true_fire_map = fire_data_dict[fire_id][doy]\n",
    "    except KeyError:\n",
    "        print(\"Not a valid fire_id and day of year combination\")\n",
    "\n",
    "    weather_data_test = weather_data[doy]\n",
    "    small_dataset_test = None\n",
    "\n",
    "    for (day, (x, y)) in small_dataset:\n",
    "        if day == doy:\n",
    "            small_dataset_test = (day, (x, y))\n",
    "\n",
    "    (day, (x, y)) = small_dataset_test\n",
    "        \n",
    "    x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "    y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "    \n",
    "    vals = np.where((y == 1) | (y == 0))\n",
    "    vals = list(zip(vals[0], vals[1]))\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    shape = x.shape\n",
    "    prediction = np.zeros(shape)\n",
    "    \n",
    "    for (xi, yi) in vals:\n",
    "        point = (xi, yi)\n",
    "        \n",
    "        xi_r = xi + side\n",
    "        xi_l = xi - side\n",
    "        yi_b = yi + side\n",
    "        yi_t = yi - side\n",
    "\n",
    "        m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "        \n",
    "        weather = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "\n",
    "        y_label = y[xi, yi]\n",
    "        \n",
    "        if (weather is not None) and (m.shape == (matrix_dim, matrix_dim)):\n",
    "            values.append((point, y_label, weather, m))\n",
    "    \n",
    "    \n",
    "    for (point, y_label, w, f) in values:        \n",
    "        fire = []\n",
    "        weather = []\n",
    "        Y = []\n",
    "\n",
    "        fire.append(np.asarray(f))\n",
    "        weather.append(np.asarray(w))\n",
    "        Y.append(y_label)\n",
    "\n",
    "        fire = np.asarray(fire)\n",
    "        weather = np.asarray(weather)\n",
    "        Y = np.asarray(Y)\n",
    "        \n",
    "        obs = len(fire)\n",
    "        fire = fire.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "        if model == model_2:\n",
    "            val = model.predict([fire, weather])\n",
    "        else:\n",
    "            raise Exception\n",
    "            \n",
    "            \n",
    "        prediction[point] = val\n",
    "    \n",
    "    x_start = matrix_dim\n",
    "    x_end = 456 + matrix_dim\n",
    "    y_start = matrix_dim\n",
    "    y_end = 470 + matrix_dim\n",
    "    \n",
    "    prediction = prediction[y_start:y_end, x_start:x_end]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Day of Fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrasterdims(geotif_filename):\n",
    "    \n",
    "    \"\"\"Get the top left and resolution for pixels in an array\n",
    "    given the tif coordinate reference system\n",
    "    Input: geotiff path+filename\n",
    "    Output: tuple of the x,y coordinate of top left and resolutions of pixel\n",
    "\n",
    "    Example to find out which pixel a given x,y coordinate refers to:\n",
    "    pixel_column = (x-left)/xres\n",
    "    pixel_row = (y-top)/yres\n",
    "    \"\"\"\n",
    "\n",
    "    with rio.open(geotif_filename) as tif:\n",
    "        profile = tif.profile\n",
    "\n",
    "    left = profile['transform'][2]\n",
    "    top = profile['transform'][5]\n",
    "\n",
    "    xres = profile['transform'][0]\n",
    "    yres = profile['transform'][4]\n",
    "\n",
    "    return ((left,top),(xres,yres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcoords(geotif,pixelrow,pixelcol):\n",
    "    \n",
    "    \"\"\"Get the coordinates of a given pixel in the tif coordinate\n",
    "    system\n",
    "    Input: geotiff path+filename, and row,column of the pixel in question\n",
    "    Output: tuple of the x,y coordinate in the geotif coordinate system\n",
    "    \"\"\"\n",
    "\n",
    "    with rio.open(geotif) as tif:\n",
    "        profile = tif.profile\n",
    "\n",
    "    left = profile['transform'][2]\n",
    "    top = profile['transform'][5]\n",
    "\n",
    "    xres = profile['transform'][0]\n",
    "    yres = profile['transform'][4]\n",
    "\n",
    "    deltax = xres*pixelcol\n",
    "    deltay = yres*pixelrow\n",
    "\n",
    "    x = left+deltax\n",
    "    y = top+deltay\n",
    "\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_polygon(fire_polygon):\n",
    "    \"\"\"Convert Coord ref system (CRS) from fire data (EPSG 3857) to map\n",
    "    lat/long (EPSG 4326), polygon starts and ends on same point (to close it)\n",
    "\n",
    "    Input: list containing tuples of x,y points in fire CRS that describe a polygon\n",
    "    Output: list containing tuples of lat/long points that describe the polygon\n",
    "    \"\"\"\n",
    "\n",
    "    # create polygon\n",
    "    poly = geometry.Polygon([(p[0], p[1]) for p in fire_polygon])\n",
    "\n",
    "    #CRS\n",
    "    src_crs = \"EPSG:3857\"\n",
    "    dst_crs = \"EPSG:4326\"\n",
    "\n",
    "    # Create Geo DataFrame\n",
    "    gfp = gpd.GeoDataFrame(index=[0],crs=src_crs,geometry=[poly])\n",
    "\n",
    "    # Convert CRS\n",
    "    gfp2 = gfp.to_crs(dst_crs)\n",
    "\n",
    "    # pull data from dataframe\n",
    "    polyout = gfp2.iloc[0]['geometry']\n",
    "\n",
    "    # create list of tuples, but longitude is first\n",
    "    l = list(map(tuple,np.asarray(polyout.exterior.coords)))\n",
    "    l = list(map(lambda m: (m[0],m[1]), l))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict fire location or that day using model 2\n",
    "pred = predict_day('140', '209', model_2, matrix_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create outline of predicted burn area\n",
    "outline = np.rint(pred)\n",
    "outline = np.diff(outline)\n",
    "outline = np.abs(outline)\n",
    "\n",
    "# get raster dims from original tif file\n",
    "tiff_file = None\n",
    "path = os.path.abspath(tif_directory)\n",
    "\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith('.tif'):\n",
    "        tiff_file = path + '/' + f\n",
    "        break\n",
    "        \n",
    "raster_dims = getrasterdims(tiff_file)\n",
    "\n",
    "# get pixels from outline\n",
    "poly_to_plot = np.where(outline != 0)\n",
    "\n",
    "# instantiate a matrix in the target shape\n",
    "shape = outline.shape\n",
    "poly = np.zeros(shape)\n",
    "\n",
    "# create a list of coordinates in the tif coordinate system\n",
    "tif_coordinates = []\n",
    "\n",
    "for (xi, yi) in list(zip(poly_to_plot[0], poly_to_plot[1])):\n",
    "        poly[xi,yi] = 1\n",
    "        coords = getcoords(tiff_file, xi, yi)\n",
    "        tif_coordinates.append(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of tif coords to lat/long\n",
    "long_lat_points = convert_polygon(tif_coordinates)                               \n",
    "                               \n",
    "# write to csv\n",
    "with open('polygon.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    headerrow = ('Longitude','Latitude')\n",
    "    writer.writerow(headerrow)\n",
    "    for point in long_lat_points:\n",
    "        writer.writerow(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
