{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import requests\n",
    "import faster_than_requests as ftreq\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"matplotlib\",matplotlib.__version__)\n",
    "print(\"seaborn\",sns.__version__)\n",
    "print(\"numpy\",np.__version__)\n",
    "print(\"pandas\",pd.__version__)\n",
    "print(\"python\",sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Forecast Data API supports HTTP compression. We heartily recommend using it, as it will make responses much smaller over the wire. To enable it, simply add an `Accept-Encoding: gzip` header to your request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together: Functions to get weather, create each day's weather from DarkSky json and to upsample each array then store the dictionary of arrays out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weather Data Functions and call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get dates of fire in pertinent area from raster file.\n",
    "def get_fire_dates(yr,path,filename):\n",
    "    \"\"\"Get all the dates for a given year that there was fire\n",
    "    in the raster being studied\n",
    "    \"\"\"\n",
    "    import rasterio as rio\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    \n",
    "    f = path+filename\n",
    "    # Use the firedata raster to find the day of year \n",
    "    with rio.open(f,'r') as rast:\n",
    "        rastdata = rast.read(1)\n",
    "    \n",
    "    # Get unique days of the year there was a pixel on a fireline, as well as counts\n",
    "    uniq = np.unique(rastdata, return_counts=True)\n",
    "    days = uniq[0]\n",
    "    counts = uniq[1]\n",
    "    \n",
    "    # Error check that counts are greater than 0\n",
    "    if np.count_nonzero(counts) > 0:\n",
    "        days = days[days > 0]  # remove the -9999 no data values\n",
    "\n",
    "    # Create list of dates for DOY on fireline, date format = ['2016-12-16']\n",
    "    # time = date+'T12:00:00'\n",
    "    fire_dates = []\n",
    "    for day in days:\n",
    "        s = yr + '-'+ str(day)\n",
    "        d = datetime.strptime(s,'%Y-%j')\n",
    "        s2 = str(d.strftime(\"%Y-%m-%d\")) + 'T12:00:00'\n",
    "        fire_dates.append(s2)\n",
    "    \n",
    "    return fire_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_weather(pairs,fire_dates,key):\n",
    "    \"\"\"Function to loop through all pairs of lat/long and get the daily weather\n",
    "    for each point from DarkSky\n",
    "    Input: list of pairs of lat/long, list of dates, API Key\n",
    "    Output: Dictionary of list of daily weather jsons\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    s = requests.Session()\n",
    "    s.auth = ('user', 'pass')\n",
    "    s.headers.update({'Accept-Encoding':'gzip'})\n",
    "\n",
    "    \n",
    "    yr_weath = {}\n",
    "    for date in fire_dates:\n",
    "        # Call function to get weather for specified date\n",
    "        data_for_date = getweather(s,pairs,date,key)\n",
    "        yr_weath.update({date:data_for_date})\n",
    "        \n",
    "    return yr_weath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getweather(s,coordinates,date,key):\n",
    "    \"\"\" Function to take the set of coordinates and get the daily\n",
    "    weather for a given date. rain, hi and low temps, humidity\n",
    "    wind speed and direction and cloud cover only.\n",
    "    \n",
    "    Called from fire_weather\n",
    "    \n",
    "    Input: Date, API Key and list of coordinate pairs (lat,long)\n",
    "    Output: list of jsons\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    # items to exclude from call\n",
    "    blocks = '[currently,minutely,hourly,alerts]'\n",
    "\n",
    "    # Units for call (km/h, deg C, kPa, mm precip)\n",
    "    units = 'ca'\n",
    "    \n",
    "    # Compression for call\n",
    "    headers = {'Accept-Encoding':'gzip'}\n",
    "    \n",
    "    data_out = []\n",
    "    for pair in coordinates:\n",
    "        lat = str(pair[0])\n",
    "        long = str(pair[1])\n",
    "        # set the query string for darksky\n",
    "        query = ('https://api.darksky.net/forecast/'+key+'/'+ \n",
    "            lat+','+long+','+date+'?exclude=' \n",
    "            +blocks+'&units='+units)\n",
    "        # Make the call to Dark Sky to get all the data for that date and location\n",
    "        r=s.get(query,headers=headers)\n",
    "        \n",
    "        # get the weather data from the request return\n",
    "        weather=r.json()\n",
    "        \n",
    "        # write the jsons as items in the output data list\n",
    "        data_out.append(weather)\n",
    "    \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(path,filename):\n",
    "    \"\"\" one time function to set limits of bounding box for weather\n",
    "    in lat / long\n",
    "    Input: raster\n",
    "    Output: pairs of lat/long, lats and longs    \n",
    "    \"\"\"\n",
    "    import rasterio as rio\n",
    "    import numpy as np\n",
    "    \n",
    "    filestring = path+filename\n",
    "    with rio.open(filestring) as f:\n",
    "        left,bottom,right,top = f.bounds\n",
    "    \n",
    "    # for rectangle\n",
    "    bb_long = [left,right,right,left,left]\n",
    "    bb_lat = [top,top,bottom,bottom,top]\n",
    "    \n",
    "    # Create grid of lat/long pairs for retrieving weather data\n",
    "    min_long = min(bb_long)\n",
    "    max_long = max(bb_long)\n",
    "    min_lat = min(bb_lat)\n",
    "    max_lat = max(bb_lat)\n",
    "\n",
    "    # 15 x 15 grid\n",
    "    spaces = 15\n",
    "    longs = np.linspace(min_long,max_long,spaces)\n",
    "    lats = np.linspace(min_lat,max_lat,spaces)\n",
    "    pairs = [(lat,long) for lat in lats for long in longs]\n",
    "    \n",
    "    return (pairs,lats,longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(year):\n",
    "    \"\"\"Function to run weather functions to get weather data from DarkSky\n",
    "    for each day in the given year there is a fire in a pixel in the area under question\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    # Non-Request related setup\n",
    "    path = '../data/GlobalFire/'+year+'/'\n",
    "    filename = 'BBfirelineCA.tif'  # use fireline to get all pixels involved in a fire in that year\n",
    "\n",
    "    # Get pairs of lats and longs\n",
    "    pairs,lats,longs = setup(path,filename)\n",
    "\n",
    "    # Get dates for required request\n",
    "    fire_dates = get_fire_dates(year,path,filename)\n",
    "\n",
    "    # Dark Sky API key (Laura Chutny)\n",
    "    key = '5ffac5f056d341c6296cba58fa96e9ba'\n",
    "    # Make requests to DarkSky\n",
    "    yr_weather = fire_weather(pairs,fire_dates,key)  # Dictionary of jsons\n",
    "\n",
    "    # Pickle out the jsons to avoid another call to API (just in case something goes wrong)\n",
    "    weathfile = path+'weatherjsons.pickle'\n",
    "    with open(weathfile,'wb') as f:\n",
    "        pickle.dump(yr_weather,f,pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"{weathfile} printed for year {year}\")\n",
    "\n",
    "    return fire_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/GlobalFire/2014/weatherjsons.pickle printed for year 2014\n",
      "../data/GlobalFire/2015/weatherjsons.pickle printed for year 2015\n",
      "../data/GlobalFire/2016/weatherjsons.pickle printed for year 2016\n",
      "Wall time: 2h 14min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# when doing with an open API session, takes about 45-55 minutes per year\n",
    "years = ['2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2014','2015','2016']\n",
    "fire_dates={}\n",
    "fire_date_nums={}\n",
    "for year in years:\n",
    "    # Commenting out this next line to make sure we don't accidentally run the weather api.\n",
    "    #fds = weather(year)\n",
    "    fire_dates[year]=fds\n",
    "    fire_date_nums[year]=len(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change jsons to dataframes and then rasters and reproject before pickling out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_point(info,rain=False):\n",
    "    \"\"\" to check if there is a value for that weather element and provide \n",
    "    either None or the value back\n",
    "    Used in function date_df only\n",
    "    \"\"\"\n",
    "    if info:\n",
    "        return info\n",
    "    elif (not info and rain):\n",
    "        return 0.0        \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def date_df(data_out):\n",
    "    \"\"\" Function to take the list of jsons for each lat/long from one date\n",
    "    of daily weather request and create a pandas dataframe\n",
    "    \n",
    "    Input: list of jsons containing the weather data for one day\n",
    "    Output: pandas dataframe\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    \n",
    "    data_convert=[]\n",
    "    # Titles for the data\n",
    "    coltitles = ['date','latitude','longitude','rainint','raintot','High T','Low T','Humidity','Wind Speed','Wind Direction','Cloud Cover']\n",
    "    data_convert.append(coltitles)\n",
    "    # Loope through all the geopoints to get the data\n",
    "    for point in data_out:\n",
    "        lat = point['latitude']\n",
    "        long = point['longitude']\n",
    "        daily = point.get('daily')\n",
    "        if daily:\n",
    "            data = daily['data'][0]\n",
    "            date = datetime.fromtimestamp(data['time']).strftime('%Y-%m-%d')\n",
    "            rainint = data.get('precipIntensityMax')\n",
    "            raintot = data.get('precipAccumulation')\n",
    "            hitemp = data.get('temperatureHigh')\n",
    "            lotemp = data.get('temperatureLow')\n",
    "            humidity = data.get('humidity')\n",
    "            windspd = data.get('windSpeed')\n",
    "            winddir = data.get('windBearing')\n",
    "            clouds = data.get('cloudCover')\n",
    "            point = [date,lat,long,check_point(rainint,1),check_point(raintot,1), \\\n",
    "                     check_point(hitemp,0),check_point(lotemp,0), \\\n",
    "                     check_point(humidity,0),check_point(windspd,0), \\\n",
    "                     check_point(winddir,0), check_point(clouds,0)] \n",
    "            data_convert.append(point)\n",
    "            \n",
    "        else:\n",
    "            point = None\n",
    "            \n",
    "    df = pd.DataFrame(data_convert[1:], columns = data_convert[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsons_to_arrays(date_jsons,pairs):\n",
    "    \"\"\" Take list of jsons for weather for area being studied (YxY jsons)\n",
    "    for 1 day and turn them into a dictionary of numpy arrays\n",
    "    \n",
    "    Input: list of jsons - 1 per lat/long point and pairs of lat/long\n",
    "    Output: dictionary of numpy arrays - 1 for each weather type for given date\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Input jsons to pandas dataframe:\n",
    "    df = date_df(date_jsons)\n",
    "          \n",
    "    # Add Missing Rows to dataframe:\n",
    "    # First get a paired list to determine if any rows are missing\n",
    "    df['xx'] = list(zip(df['latitude'],df['longitude']))\n",
    "    missing = pd.DataFrame({'xx':list(set(df['xx']) ^ set(pairs))})\n",
    "    if not missing.empty:\n",
    "        missing[['latitude','longitude']]=pd.DataFrame(missing['xx'].tolist(),index=missing.index)\n",
    "        df = df.append(missing, ignore_index=True, sort=True)\n",
    "    \n",
    "    # Sort DataFrame to allow creation of rows in array.\n",
    "    weather = ['rainint','raintot','High T','Low T','Humidity','Wind Speed','Wind Direction','Cloud Cover']\n",
    "    weath_sort = df.to_records(index=False)\n",
    "    weath_sort.sort(order=('latitude','longitude'))\n",
    "\n",
    "    # Create Dictionary of Numpy Arrays\n",
    "    weather_date = {}\n",
    "    for var in weather:\n",
    "        x = weath_sort[var].reshape(15,15)\n",
    "        xx = np.flip(x,0)\n",
    "        weather_date.update({var:xx})\n",
    "        \n",
    "    return weather_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_meta(lats,longs):\n",
    "    \"\"\" Calculate transform and meta data for 15x15 \n",
    "    raster of lat/long data\n",
    "    \"\"\"\n",
    "    \n",
    "    # from https://rasterio.readthedocs.io/en/latest/quickstart.html#creating-data\n",
    "    # See my imported sketches with the correct transforms\n",
    "    \n",
    "    #  Resolution\n",
    "    xres = (longs[-1] - longs[0]) / 14\n",
    "    yres = (lats[0] - lats[-1]) /14\n",
    "    \n",
    "    # affine transform - assumes each lat/long point is in the center of the pixel it represents\n",
    "    src_transform = Affine.translation(longs[0] - xres / 2, lats[-1] - yres / 2) * Affine.scale(xres, yres)\n",
    "    \n",
    "    meta = {'driver':'GTiff','height':15, \\\n",
    "                'width':15,'count':1, \\\n",
    "                'dtype':'float64', 'crs':'+proj=latlong', \\\n",
    "                'transform':src_transform, 'nodata':-9999, \\\n",
    "                'compress':'lzw','interleave':'band'}\n",
    "    \n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_arrs(arrs,path,filename,src_meta):\n",
    "    \"\"\"Reproject the lat/long weather arrays to\n",
    "    raster arrays with new CRS\n",
    "    \n",
    "    Input: Dictionary of numpy arrays holding 8 weather variables\n",
    "    for one date in 15x15 grid based on lat/long, path and filename to raster\n",
    "    and Source meta data\n",
    "    Output: Dictionary of numpy arrays holding 8 weather variables\n",
    "    for one date in grid to match firedata raster.\n",
    "    \"\"\"    \n",
    "    # Get reference meta data from raster\n",
    "    file = path+filename\n",
    "    with rio.open(file,'r') as ref:\n",
    "        refdata = ref.read(1)  # data in raster\n",
    "        refmeta = ref.meta # meta data in raster\n",
    "        refres = ref.res # resolution in raster\n",
    "    \n",
    "    # Set destination transform and coordinate reference system\n",
    "    dst_transform = refmeta['transform']\n",
    "    dst_crs = refmeta['crs']\n",
    "\n",
    "    # Get source transform and CRS\n",
    "    src_transform = src_meta['transform']\n",
    "    src_crs = src_meta['crs']\n",
    "    \n",
    "    refmeta['dtype'] = 'float64'\n",
    "    \n",
    "    dst_shape = refdata.shape\n",
    "    destination = np.full(dst_shape, -9999.0)\n",
    "    \n",
    "    rp = {}\n",
    "    for w,a in arrs.items():\n",
    "        # clear the array before reprojecting each time\n",
    "        destination = np.full(dst_shape, -9999.0)\n",
    "        \n",
    "        reproject(\n",
    "            a,\n",
    "            destination,\n",
    "            src_transform=src_transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear)\n",
    "        \n",
    "        rp.update({str(w):destination})\n",
    "\n",
    "    return rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get jsons into matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to loop over all dates and write out the dictionary of basic arrays (not reprojected)\n",
    "def all_weather(year):\n",
    "    \"\"\"Loop through all the dates for fire in a year and\n",
    "    corresponding daily weather jsons (yr_weather), convert\n",
    "    to numpy arrays and reproject the arrays, then save out the new dictionary\n",
    "    \n",
    "    Input: yearly weather pickled jsons from darksky as date keyed dictionary of jsons, with lat/long pairs as pairs and separate lists\n",
    "    Output: write out the reprojected yearly weather arrays as pickle file\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    import pickle\n",
    "    \n",
    "    # Non-Request related setup\n",
    "    path = '../data/GlobalFire/'+year+'/'\n",
    "    filename = 'BBfirelineCA.tif'  # use fireline to get all pixels involved in a fire in that year\n",
    "    weatherjsons = 'weatherjsons.pickle'  # use fireline to get all pixels involved in a fire in that year\n",
    "\n",
    "    # Get pairs of lats and longs\n",
    "    pairs,lats,longs = setup(path,filename)\n",
    "\n",
    "    wj = path+weatherjsons\n",
    "    with open(wj,'rb') as f:\n",
    "        wj2 = pickle.load(f)   \n",
    "    \n",
    "    yr_weather={}\n",
    "    for date,data in wj2.items():\n",
    "        # Convert jsons to arrays for given date\n",
    "        day_data = jsons_to_arrays(data,pairs)  #dictionary of numpy arrays - 1 array for each weather variable keyed by date\n",
    "        dt = date[0:10]\n",
    "        \n",
    "        yr_weather.update({dt:day_data})\n",
    "        \n",
    "    # Pickle out the array dictionary:\n",
    "    wafile = path+'weatherarrays.pickle'\n",
    "    with open(wafile,'wb') as f2:\n",
    "        pickle.dump(yr_weather,f2,pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(f\"Jsons turned to arrays for year {year} and saved out\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jsons turned to arrays for year 2003 and saved out\n",
      "Jsons turned to arrays for year 2004 and saved out\n",
      "Jsons turned to arrays for year 2005 and saved out\n",
      "Jsons turned to arrays for year 2006 and saved out\n",
      "Jsons turned to arrays for year 2007 and saved out\n",
      "Jsons turned to arrays for year 2008 and saved out\n",
      "Jsons turned to arrays for year 2009 and saved out\n",
      "Jsons turned to arrays for year 2010 and saved out\n",
      "Jsons turned to arrays for year 2011 and saved out\n",
      "Jsons turned to arrays for year 2012 and saved out\n",
      "Jsons turned to arrays for year 2014 and saved out\n",
      "Jsons turned to arrays for year 2015 and saved out\n",
      "Jsons turned to arrays for year 2016 and saved out\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "years = ['2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2014','2015','2016']\n",
    "for year in years:\n",
    "    all_weather(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reprojected arrays for each date and pickle out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to loop over all dates and write out the dictionary\n",
    "def reproj_weather(yr_weather,pairs,lats,longs):\n",
    "    \"\"\"Loop through all the dates for fire in a year and\n",
    "    corresponding daily weather jsons (yr_weather), convert\n",
    "    to numpy arrays and reproject the arrays, then save out the new dictionary\n",
    "    \n",
    "    Input: yearly weather from darksky as date keyed dictionary of jsons, with lat/long pairs as pairs and separate lists\n",
    "    Output: write out the reprojected yearly weather arrays as pickle file\n",
    "    \"\"\"\n",
    "    \n",
    "    yr_rp_weather = {}    \n",
    "    for date,data in yr_weather.items():\n",
    "        # Convert jsons to arrays for given date\n",
    "        day_data = jsons_to_arrays(data,pairs)  #dictionary of numpy arrays - 1 array for each weather variable keyed by date\n",
    "        \n",
    "        # Reproject arrays\n",
    "        reproj = reproject_arrs(day_data,path,filename,new_meta(lats,longs))\n",
    "        dt = date[0:10]\n",
    "        \n",
    "        yr_rp_weather.update({dt:reproj})\n",
    "        \n",
    "    # Pickle out the reprojected array dictionary:\n",
    "    with open('../data/GlobalFire2016/weather2016data.pickle','wb') as f:\n",
    "        pickle.dump(yr_rp_weather,f,pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return (len(yr_rp_weather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/GlobalFire/2014/weatherjsons.pickle printed for year 2014\n",
      "../data/GlobalFire/2015/weatherjsons.pickle printed for year 2015\n",
      "../data/GlobalFire/2016/weatherjsons.pickle printed for year 2016\n",
      "Wall time: 2h 14min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "years = ['2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2014','2015','2016']\n",
    "for year in years:\n",
    "    reproj_weather(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if data correctly reprojected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weather(day_weath):\n",
    "    \"\"\" Plot all the weather components for that day\"\"\"\n",
    "    fig = plt.figure(figsize = (20,8))\n",
    "    fig.subplots_adjust(hspace=0.4,wspace=0.4)\n",
    "    i=1\n",
    "    for key,data in day_weath.items():\n",
    "        ax = fig.add_subplot(2,4,i)\n",
    "        sns.heatmap(data)\n",
    "        ax.set_title(key)\n",
    "        i+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = y1[0]\n",
    "plot_weather(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    #path = '../data/GlobalFire/'+year+'/'   \n",
    "    #filename = 'weather'+year+'data.pickle'\n",
    "    #filestring = path+filename\n",
    "    filestring='../data/GlobalFire2016/weather2016data.pickle'\n",
    "    with open(filestring,'rb') as f:\n",
    "        y1 = pickle.load(f)\n",
    "    x1 = y[1] #arbitrary day\n",
    "    print(f\"Year{year}\")\n",
    "    plot_weather(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return from pickle for further work\n",
    "import pickle\n",
    "with open('../data/GlobalFire/2003/weatherarrays.pickle','rb') as f:\n",
    "    z = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2003-01-10', '2003-01-11', '2003-01-12', '2003-01-13', '2003-01-14', '2003-01-15', '2003-01-16', '2003-01-17', '2003-02-25', '2003-02-26', '2003-02-27', '2003-02-28', '2003-03-01', '2003-03-02', '2003-03-03', '2003-03-04', '2003-03-05', '2003-03-06', '2003-03-07', '2003-03-08', '2003-03-09', '2003-03-10', '2003-03-11', '2003-03-12', '2003-03-14', '2003-03-15', '2003-03-16', '2003-03-17', '2003-03-18', '2003-03-19', '2003-03-20', '2003-03-21', '2003-03-22', '2003-03-23', '2003-03-25', '2003-03-30', '2003-05-02', '2003-05-03', '2003-05-04', '2003-05-05', '2003-05-06', '2003-05-07', '2003-05-08', '2003-05-09', '2003-05-10', '2003-05-11', '2003-05-18', '2003-05-19', '2003-05-20', '2003-05-21', '2003-05-22', '2003-05-26', '2003-05-29', '2003-05-30', '2003-05-31', '2003-06-01', '2003-06-02', '2003-06-03', '2003-06-04', '2003-06-05', '2003-06-07', '2003-06-08', '2003-06-15', '2003-06-16', '2003-06-17', '2003-06-18', '2003-06-19', '2003-06-20', '2003-06-21', '2003-07-03', '2003-07-09', '2003-07-16', '2003-07-19', '2003-07-20', '2003-07-21', '2003-07-22', '2003-07-23', '2003-07-24', '2003-07-31', '2003-08-01', '2003-08-02', '2003-08-03', '2003-08-04', '2003-08-05', '2003-08-06', '2003-08-07', '2003-08-08', '2003-08-09', '2003-08-10', '2003-08-11', '2003-08-12', '2003-08-13', '2003-08-15', '2003-08-16', '2003-08-21', '2003-08-22', '2003-08-23', '2003-08-24', '2003-08-25', '2003-08-26', '2003-08-27', '2003-08-28', '2003-08-29', '2003-08-30', '2003-08-31', '2003-09-01', '2003-09-02', '2003-09-03', '2003-09-04', '2003-09-05', '2003-09-06', '2003-09-07', '2003-09-08', '2003-09-09', '2003-09-11', '2003-09-12', '2003-09-13', '2003-09-14', '2003-09-15', '2003-09-16', '2003-09-17', '2003-09-18', '2003-09-19', '2003-09-20', '2003-09-21', '2003-09-22', '2003-09-23', '2003-09-24', '2003-09-25', '2003-09-26', '2003-09-27', '2003-09-28', '2003-09-29', '2003-09-30', '2003-10-01', '2003-10-03', '2003-10-05', '2003-10-06', '2003-10-07', '2003-10-08', '2003-10-09', '2003-10-10', '2003-10-13', '2003-10-14', '2003-10-15', '2003-10-16', '2003-10-21', '2003-10-22', '2003-10-23', '2003-10-24', '2003-10-25', '2003-10-26', '2003-11-04', '2003-11-05', '2003-11-06', '2003-11-07', '2003-11-08', '2003-11-10', '2003-11-11', '2003-11-12', '2003-11-13', '2003-11-14', '2003-11-15', '2003-11-16', '2003-11-17', '2003-11-18', '2003-11-19', '2003-11-20', '2003-11-21', '2003-11-22', '2003-11-23', '2003-11-24', '2003-11-25', '2003-11-26', '2003-11-27', '2003-11-28', '2003-11-29', '2003-11-30', '2003-12-03'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rainint': array([[0.9702, 0.9702, 0.9702, 0.9702, 0.    , 2.7517, 2.473 , 2.419 ,\n",
       "         0.8465, 0.9848, 1.8516, 1.1331, 0.0717, 0.1063, 0.    ],\n",
       "        [0.9702, 3.8798, 3.8971, 3.9528, 0.    , 1.5999, 1.501 , 1.4853,\n",
       "         0.965 , 0.9324, 0.9324, 0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 2.5029, 3.3918, 3.55  , 2.4995, 1.59  , 0.9964, 0.7679,\n",
       "         0.7085, 0.633 , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 2.4435, 2.4666, 2.6715, 3.4977, 1.5881, 1.2398, 0.7357,\n",
       "         0.7568, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 2.4542, 2.64  , 4.0307, 3.0753, 1.5263, 1.0216,\n",
       "         1.3509, 1.625 , 0.    , 0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.    , 1.9933, 2.2483, 2.4402, 0.875 , 1.2099,\n",
       "         1.6201, 1.5308, 1.6079, 0.    , 0.    , 0.    , 0.    ],\n",
       "        [   nan, 0.    , 0.    , 1.5207, 1.5547, 1.0084, 1.0832, 0.9587,\n",
       "         1.5318, 1.5854, 1.7935, 2.5451, 0.    , 0.    , 0.    ],\n",
       "        [   nan, 0.    , 0.    , 1.5176, 1.6086, 1.025 , 1.1434, 1.0401,\n",
       "         1.5469, 1.674 , 2.0357, 2.5451, 2.5451, 0.    , 0.    ],\n",
       "        [   nan,    nan, 0.    , 2.0318, 1.3416, 1.4876, 1.5757, 3.7324,\n",
       "         2.3507, 1.9834, 2.4679, 2.4996, 2.3166, 2.1718, 0.    ],\n",
       "        [   nan,    nan, 0.    , 0.    , 0.    , 2.4814, 2.8467, 3.9691,\n",
       "         0.    , 2.4899, 2.4528, 2.3178, 2.1677, 2.1911, 2.2865],\n",
       "        [   nan,    nan, 0.    , 0.    , 0.    , 1.9334, 2.4552, 4.1958,\n",
       "         4.5567, 0.    , 2.3496, 2.1904, 2.1506, 2.2698, 2.2858],\n",
       "        [   nan,    nan, 0.    , 0.    , 2.5736, 2.2788, 2.4296, 2.9899,\n",
       "         4.067 , 0.    , 0.    , 1.9576, 2.0951, 2.1462, 1.7654],\n",
       "        [   nan,    nan,    nan, 0.    , 2.2014, 2.4089, 2.4285, 2.0937,\n",
       "         3.2367, 0.    , 0.    , 0.    , 0.    , 1.4488, 1.1443],\n",
       "        [   nan,    nan,    nan,    nan, 0.    , 2.6053, 2.6234, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 1.0332],\n",
       "        [   nan,    nan,    nan,    nan,    nan, 0.    , 0.    , 3.1076,\n",
       "         3.1076, 1.4342, 0.8903, 0.8903, 0.    , 0.    , 1.0181]]),\n",
       " 'raintot': array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 4.4, 0.1,\n",
       "         0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ],\n",
       "        [nan, nan, nan, nan, nan, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "         0. , 0. ]]),\n",
       " 'High T': array([[11.13, 11.67, 10.54, 10.44, 12.57, 13.55, 13.8 , 13.94, 13.12,\n",
       "         10.4 ,  5.89,  2.1 ,  3.77,  6.71,  3.37],\n",
       "        [13.64, 12.13, 11.11, 10.66, 10.97, 13.36, 13.73, 14.3 , 13.93,\n",
       "         11.9 ,  8.55,  4.18,  0.16,  6.12,  2.49],\n",
       "        [13.66, 11.82, 12.33, 12.97, 11.88, 11.9 , 13.65, 14.21, 14.13,\n",
       "         14.37,  8.63,  5.23,  0.53,  2.04,  6.26],\n",
       "        [13.71, 13.64, 13.09, 13.32, 13.36, 10.07, 13.44, 14.09, 14.37,\n",
       "         13.84,  9.91,  4.1 ,  0.83,  0.21,  2.87],\n",
       "        [13.83, 13.68, 13.43, 12.15, 14.41, 14.46, 13.74, 14.06, 14.43,\n",
       "         14.  , 11.4 ,  9.14,  4.38, -0.22, -0.72],\n",
       "        [13.79, 13.68, 13.82, 12.07, 15.01, 15.21, 14.94, 15.26, 14.33,\n",
       "         13.9 , 12.18, 10.27,  6.77,  4.14,  3.09],\n",
       "        [  nan, 13.78, 13.83, 14.78, 15.84, 15.37, 15.6 , 14.75, 14.3 ,\n",
       "         14.22, 14.  , 12.31,  7.99,  4.65,  0.04],\n",
       "        [  nan, 13.78, 13.87, 15.74, 16.04, 17.17, 12.8 ,  9.83, 13.72,\n",
       "         14.3 , 14.09, 13.64, 10.22,  6.75, -0.22],\n",
       "        [  nan,   nan, 15.09, 15.79, 14.5 , 14.32, 15.58, 11.3 , 12.73,\n",
       "         14.17, 14.37, 14.1 , 12.8 , 11.61,  9.18],\n",
       "        [  nan,   nan, 15.09, 14.56, 14.93, 13.84, 12.85, 14.43, 13.03,\n",
       "         14.35, 14.25, 14.29, 14.17, 13.68, 10.94],\n",
       "        [  nan,   nan, 14.  , 14.12, 14.02, 16.52, 17.34, 17.48, 14.43,\n",
       "         13.63, 14.12, 14.5 , 14.43, 14.31, 13.74],\n",
       "        [  nan,   nan, 14.  , 14.  , 14.44, 17.43, 18.28, 16.99, 15.21,\n",
       "         13.23, 14.05, 14.49, 14.79, 14.42, 13.81],\n",
       "        [  nan,   nan,   nan, 14.  , 15.42, 17.22, 14.21, 12.95, 16.11,\n",
       "         11.29, 10.21, 13.99, 15.39, 14.96, 14.37],\n",
       "        [  nan,   nan,   nan,   nan, 15.56, 16.57, 17.19, 16.68, 16.22,\n",
       "         13.15,  8.33, 13.61, 14.82, 14.87, 14.45],\n",
       "        [  nan,   nan,   nan,   nan,   nan, 15.27, 16.06, 14.96, 16.31,\n",
       "         14.99, 13.62, 13.1 , 12.71, 14.56, 14.62]]),\n",
       " 'Low T': array([[ 8.2 ,  7.33,  6.98,  6.7 ,  7.6 , 10.09,  9.06,  8.86,  8.37,\n",
       "          6.49,  2.92, -2.21, -2.84, -0.25, -3.53],\n",
       "        [10.65,  8.56,  7.99,  7.18,  7.54,  9.94,  9.08,  8.6 ,  7.9 ,\n",
       "          6.66,  3.74, -1.77, -6.76, -3.72, -4.35],\n",
       "        [12.  ,  8.83,  8.63,  9.96,  8.8 ,  8.88,  8.98,  8.44,  7.15,\n",
       "          7.98,  3.15,  0.24, -6.35, -6.15, -3.22],\n",
       "        [12.29, 11.77, 10.8 , 10.43, 10.11,  6.54,  9.26,  8.42,  8.25,\n",
       "          8.49,  4.11, -0.97, -4.51, -6.33, -4.16],\n",
       "        [12.4 , 12.21, 11.35, 10.1 , 10.73, 10.65, 10.32, 10.2 ,  8.89,\n",
       "          9.04,  6.13,  3.48, -1.19, -7.6 , -9.92],\n",
       "        [12.62, 12.33, 12.43,  9.69, 11.71, 10.56, 10.99, 10.28,  8.64,\n",
       "          8.29,  7.15,  5.77,  1.42, -1.53, -6.53],\n",
       "        [  nan, 12.5 , 12.53, 12.15, 11.29, 10.35,  7.57, 10.3 ,  8.71,\n",
       "          7.78,  7.97,  6.8 ,  2.89,  0.84, -5.91],\n",
       "        [  nan, 12.5 , 12.49, 11.53, 10.35,  9.99,  9.96,  5.43, 10.  ,\n",
       "          7.9 ,  6.23,  6.22,  3.5 ,  0.91, -6.3 ],\n",
       "        [  nan,   nan, 11.52, 11.47,  9.6 ,  9.35,  8.67,  5.13,  9.04,\n",
       "          7.71,  3.38,  4.04,  5.49,  4.94,  0.56],\n",
       "        [  nan,   nan, 11.52, 11.72, 11.54,  8.18,  2.29,  5.88,  6.6 ,\n",
       "          7.14,  2.8 ,  3.29,  3.3 ,  4.37,  0.85],\n",
       "        [  nan,   nan, 12.23, 12.2 , 12.23,  7.1 , -0.18,  7.3 ,  4.54,\n",
       "          5.72,  2.67,  3.14,  3.39,  4.66,  7.3 ],\n",
       "        [  nan,   nan, 12.23, 12.23, 11.9 ,  9.33,  8.55,  7.86,  5.04,\n",
       "          6.51, 10.15,  5.16,  3.9 ,  4.37,  5.33],\n",
       "        [  nan,   nan,   nan, 12.23, 11.15, 10.  ,  6.49,  3.83,  4.68,\n",
       "          6.52,  7.48,  9.94,  5.59,  3.86,  3.73],\n",
       "        [  nan,   nan,   nan,   nan, 10.39, 10.38, 10.09,  5.05,  5.55,\n",
       "          6.98,  4.26,  8.9 ,  5.5 ,  3.76,  3.85],\n",
       "        [  nan,   nan,   nan,   nan,   nan, 11.23, 10.44,  7.23,  2.51,\n",
       "          7.3 ,  6.  ,  4.7 ,   nan,  4.81,  4.6 ]]),\n",
       " 'Humidity': array([[1.  , 0.9 , 0.88, 0.94, 0.88, 0.88, 0.95, 0.92, 0.89, 0.89, 0.92,\n",
       "         1.  , 0.9 , 0.78, 0.97],\n",
       "        [0.82, 0.88, 0.91, 1.  , 0.98, 0.97, 0.97, 0.94, 0.93, 0.97, 0.88,\n",
       "         0.97, 1.  , 0.88, 0.97],\n",
       "        [0.88, 0.99, 1.  , 0.98, 1.  , 1.  , 0.97, 0.93, 0.95, 0.93, 1.  ,\n",
       "         0.98, 1.  , 0.98, 0.75],\n",
       "        [0.87, 0.91, 0.94, 0.99, 0.98, 1.  , 0.95, 0.94, 0.9 , 0.85, 0.91,\n",
       "         1.  , 1.  , 1.  , 0.88],\n",
       "        [0.89, 0.87, 0.94, 1.  , 0.92, 0.88, 0.88, 0.86, 0.88, 0.82, 0.8 ,\n",
       "         0.84, 0.99, 1.  , 0.98],\n",
       "        [ nan, 0.87, 0.88, 1.  , 0.88, 0.85, 0.8 , 0.82, 0.96, 0.91, 0.89,\n",
       "         0.86, 0.93, 0.78, 0.72],\n",
       "        [ nan,  nan, 0.88, 0.89, 0.87, 0.9 , 0.88, 0.81, 0.93, 0.93, 0.89,\n",
       "         0.82, 0.91, 0.86, 1.  ],\n",
       "        [ nan,  nan, 0.89, 0.87, 0.91, 0.81, 0.83, 1.  , 0.85, 0.92, 0.92,\n",
       "         0.81, 0.96, 1.  , 1.  ],\n",
       "        [ nan,  nan, 0.94, 0.87, 0.96, 0.9 , 0.87, 1.  , 0.92, 0.95, 0.94,\n",
       "         0.89, 0.82, 0.84, 0.94],\n",
       "        [ nan,  nan, 0.94, 0.89, 0.85, 0.87, 1.  , 0.98, 1.  , 0.96, 0.97,\n",
       "         0.91, 0.9 , 0.84, 0.93],\n",
       "        [ nan,  nan,  nan, 0.95, 0.83, 0.86, 0.9 , 0.89, 0.99, 1.  , 0.96,\n",
       "         0.91, 0.9 , 0.88, 0.9 ],\n",
       "        [ nan,  nan,  nan,  nan, 0.89, 0.86, 0.85, 0.91, 0.96, 0.86, 0.64,\n",
       "         0.77, 0.89, 0.9 , 0.83],\n",
       "        [ nan,  nan,  nan,  nan, 0.9 , 0.86, 0.98, 0.99, 0.89, 0.86, 0.76,\n",
       "         0.66, 0.87, 0.94, 0.94],\n",
       "        [ nan,  nan,  nan,  nan, 0.93, 0.88, 0.84, 0.93, 0.84, 0.81, 0.94,\n",
       "         0.76, 0.86, 0.93, 0.94],\n",
       "        [ nan,  nan,  nan,  nan,  nan, 0.88, 0.83, 0.9 , 0.88, 0.84, 0.91,\n",
       "         0.96, 0.9 , 0.87, 0.9 ]]),\n",
       " 'Wind Speed': array([[16.82, 13.35, 13.13,  9.68,  4.84,  8.33, 12.96, 12.18, 10.2 ,\n",
       "          9.9 ,  7.9 ,  6.32,  4.95,  4.61,  4.99],\n",
       "        [18.16, 10.59, 11.27,  6.64,  7.46,  6.92, 11.73, 11.89,  7.62,\n",
       "          8.77,  8.54,  2.56,  4.56,  4.71,  3.42],\n",
       "        [19.26,  9.07,  5.22,  4.44,  5.06,  8.23, 11.63,  5.76, 10.37,\n",
       "          7.4 ,  7.84,  3.28,  3.33,  4.63,  5.17],\n",
       "        [17.84, 13.41,  8.2 ,  5.33,  7.54,  9.84, 11.23, 11.38, 12.26,\n",
       "         13.58,  8.65,  4.8 ,  6.01,  4.66,  4.83],\n",
       "        [18.77, 15.66,  8.12,  7.23, 10.85, 12.63, 14.3 , 15.66, 19.5 ,\n",
       "         19.58,  7.33, 11.48, 12.32,  7.97,  3.48],\n",
       "        [19.27, 15.44, 12.64,  7.97, 11.43, 14.21, 17.61, 15.02, 19.85,\n",
       "         16.2 ,  8.41, 10.03,  7.31,  5.45,  2.74],\n",
       "        [  nan, 19.01, 17.47, 14.82, 14.05, 12.6 ,  7.46, 12.47, 15.59,\n",
       "         11.96,  7.63,  6.82,  5.41,  9.8 ,  3.52],\n",
       "        [  nan, 19.01, 19.81, 14.32, 10.59, 11.2 , 13.24, 10.85, 10.09,\n",
       "         10.75,  9.95,  6.17,  4.65,  2.72,  2.39],\n",
       "        [  nan,   nan,   nan, 10.06,  7.58,  8.64, 12.8 ,  8.99,  6.25,\n",
       "          7.95, 10.91, 10.48,  5.53,  3.55,  1.42],\n",
       "        [  nan,   nan,   nan, 13.38, 10.49,  9.66,  5.81,  7.06,  5.88,\n",
       "          5.62,  9.19, 11.76, 11.65,  4.4 ,  2.35],\n",
       "        [  nan,   nan, 17.92, 17.92, 17.68,  9.5 ,  6.28,  9.91,  8.47,\n",
       "          6.51,  8.92, 12.22, 10.78,  6.46,  3.5 ],\n",
       "        [  nan,   nan, 17.92, 17.92, 16.82,  9.16,  6.16,  9.  ,  7.74,\n",
       "         11.09, 16.86, 13.98,  9.24,  7.05,  4.8 ],\n",
       "        [  nan,   nan,   nan, 17.92, 13.68,  7.82,  6.51,  5.55,  6.94,\n",
       "         15.56, 18.07, 17.56, 12.05,  7.39,  5.13],\n",
       "        [  nan,   nan,   nan,   nan,  8.29,  6.1 ,  2.45,  0.9 ,  6.13,\n",
       "         13.67, 15.67, 13.98, 12.74,  8.14,  4.88],\n",
       "        [  nan,   nan,   nan,   nan,   nan, 10.57,  7.83,  8.3 ,  7.31,\n",
       "          9.2 ,  7.63,  6.19, 13.56,  9.95,  4.87]]),\n",
       " 'Wind Direction': array([[141., 148., 174., 188., 196., 172., 152., 150., 147., 150., 176.,\n",
       "         224., 189., 191., 190.],\n",
       "        [145., 147., 136., 181., 194., 152., 149., 149., 138., 139., 173.,\n",
       "         203., 185., 191., 284.],\n",
       "        [155., 158., 161., 208., 175., 149., 149., 141., 150., 154., 149.,\n",
       "         203., 196., 194., 161.],\n",
       "        [174., 166., 168., 199., 157., 146., 149., 151., 155., 158., 128.,\n",
       "         142., 141., 209., 250.],\n",
       "        [176., 172., 163., 173., 159., 176., 181., 169., 159., 162., 141.,\n",
       "         120., 122., 132., 274.],\n",
       "        [178., 170., 170., 175., 180., 185., 200., 179., 147., 149., 127.,\n",
       "         115., 114., 142., 179.],\n",
       "        [ nan, 170., 172., 174., 171., 174., 189., 174., 145., 138., 121.,\n",
       "         112., 112., 147., 152.],\n",
       "        [ nan, 170., 179., 181., 177., 164., 153., 150., 146., 135., 120.,\n",
       "          98.,  77.,  90., 124.],\n",
       "        [ nan,  nan,  nan, 193., 182., 164., 140., 150., 149., 127., 117.,\n",
       "         111.,  92.,  79.,  72.],\n",
       "        [ nan,  nan,  nan, 183., 205., 227., 180., 149., 131., 124., 119.,\n",
       "         111., 107.,  96.,  86.],\n",
       "        [ nan,  nan, 169., 169., 170., 189., 201., 137., 133., 128., 116.,\n",
       "         109., 106.,  98., 147.],\n",
       "        [ nan,  nan, 169., 169., 170., 178., 181., 136., 142., 191., 216.,\n",
       "         172., 106.,  99.,  94.],\n",
       "        [ nan,  nan,  nan, 169., 169., 161., 158., 147., 152., 176., 240.,\n",
       "         229., 140., 114., 103.],\n",
       "        [ nan,  nan,  nan,  nan, 130., 143., 149., 218., 154., 183., 234.,\n",
       "         206., 150., 127., 103.],\n",
       "        [ nan,  nan,  nan,  nan,  nan, 163., 161., 150., 131., 143., 156.,\n",
       "         161., 156., 144.,  93.]]),\n",
       " 'Cloud Cover': array([[0.95, 0.95, 0.95, 0.95,  nan, 0.99, 0.99, 0.99, 0.97, 0.97, 0.99,\n",
       "         0.97, 0.96, 0.96, 0.95],\n",
       "        [0.95, 0.97, 0.97, 0.98,  nan, 1.  , 0.99, 0.99, 0.98, 0.97, 0.97,\n",
       "         0.95, 0.95, 0.95, 0.95],\n",
       "        [ nan, 0.98, 0.98, 0.98, 0.98, 0.99, 0.99, 0.99, 0.99, 0.98,  nan,\n",
       "         0.95, 0.95, 0.95,  nan],\n",
       "        [ nan, 0.98, 0.98, 0.98, 0.98, 0.99, 0.99, 0.99, 0.99, 0.98,  nan,\n",
       "          nan,  nan,  nan,  nan],\n",
       "        [ nan,  nan, 0.98, 0.98, 0.97, 0.98, 0.98, 0.96, 0.93, 0.89,  nan,\n",
       "          nan,  nan,  nan,  nan],\n",
       "        [ nan,  nan,  nan, 0.94, 0.95, 0.97, 0.91, 0.88, 0.89, 0.92, 0.97,\n",
       "          nan,  nan,  nan,  nan],\n",
       "        [ nan,  nan,  nan, 0.9 , 0.9 , 0.91, 0.78, 0.85, 0.92, 0.96, 0.95,\n",
       "         0.89,  nan,  nan,  nan],\n",
       "        [ nan,  nan,  nan, 0.89, 0.85, 0.81, 0.81, 0.81, 0.95, 0.97, 0.93,\n",
       "         0.89, 0.89,  nan,  nan],\n",
       "        [ nan,  nan,  nan, 0.86, 0.81, 0.79, 0.83, 0.87, 0.91, 0.93, 0.9 ,\n",
       "         0.88, 0.85, 0.81,  nan],\n",
       "        [ nan,  nan,  nan,  nan, 0.75, 0.86, 0.92, 0.88, 0.84, 0.87, 0.87,\n",
       "         0.85, 0.81, 0.78, 0.76],\n",
       "        [ nan,  nan,  nan,  nan,  nan, 0.86, 0.94, 0.85, 0.84, 0.84, 0.85,\n",
       "         0.82, 0.79, 0.77, 0.76],\n",
       "        [ nan,  nan,  nan,  nan, 0.75, 0.78, 0.77, 0.86, 0.85,  nan,  nan,\n",
       "         0.81, 0.79, 0.76, 0.73],\n",
       "        [ nan,  nan,  nan,  nan, 0.75, 0.76, 0.77, 0.8 , 0.87,  nan,  nan,\n",
       "         0.81, 0.82, 0.76, 0.69],\n",
       "        [ nan,  nan,  nan,  nan,  nan, 0.75, 0.75,  nan,  nan,  nan,  nan,\n",
       "         0.81, 0.82, 0.75, 0.66],\n",
       "        [ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan, 0.74, 0.74,\n",
       "         0.74, 0.81, 0.73, 0.59]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['2003-01-10']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
