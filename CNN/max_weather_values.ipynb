{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Max Weather Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get max weather values for each weather variable over the entire time period for scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# s3 config\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# name of directory with weather data\n",
    "weather_directory = 'weather_data'\n",
    "\n",
    "# name of key to save max values to\n",
    "key_name = 'BayAreaWeather/max_values/max_values.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Pull and Save Data to/from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_weather_data_from_s3(year, weather_directory):\n",
    "    '''\n",
    "    Pull files from S3 for the provided year and save to local directory\n",
    "    '''\n",
    "    \n",
    "    file_name = \"weather_data.pickle\"\n",
    "        \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    key = \"BayAreaWeather/\" + str(year) + \"/\" + file_name\n",
    "    path = '/home/ubuntu/wildfireplus/weather_data/' + file_name\n",
    "        \n",
    "    s3.Bucket('hotzone').download_file(key, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_s3(s3_client, array, bucket_name, key_name):\n",
    "    '''\n",
    "    Uploads pre-processed data to S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - array: numpy array to save to s3\n",
    "        - bucket_name: name of bucket on s3 to save array to\n",
    "        - key_name: directory/file_name to save data to\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    pickle.dump(array, array_data)\n",
    "    array_data.seek(0)\n",
    "    \n",
    "    s3_client.upload_fileobj(array_data, bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Calculate the Max Weather Value for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(weather_directory):\n",
    "    \n",
    "    '''\n",
    "    Iterate over all years and get max value for each attribute\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(weather_directory)\n",
    "\n",
    "    weather_file = ''\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.pickle'):\n",
    "            weather_file = path + '/' + f\n",
    "\n",
    "    weather = pd.read_pickle(weather_file)\n",
    "\n",
    "    for day, attrs in weather.items():\n",
    "        for attr, mat in attrs.items():\n",
    "            mat = np.nan_to_num(mat)\n",
    "            \n",
    "            if attr in ['High T', 'Low T']:\n",
    "                mat += 273.15\n",
    "            \n",
    "            if mat.max() > max_values[attr]:\n",
    "                max_values[attr] = mat.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Pull Weather Maxes from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_weather_maxes_from_s3():\n",
    "    '''\n",
    "    Pull files from S3 for the provided year and save to local directory\n",
    "    '''\n",
    "    \n",
    "        \n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    key = \"BayAreaWeather/max_values/max_values.pickle\"\n",
    "    directory = '/home/ubuntu/wildfireplus/weather_max/'\n",
    "    path = directory + 'max_values.pickle'\n",
    "    \n",
    "    s3.Bucket('hotzone').download_file(key, path)\n",
    "    \n",
    "    total_path = os.path.abspath(directory)\n",
    "    \n",
    "    for f in os.listdir(total_path):\n",
    "        if f.endswith('.pickle'):\n",
    "            max_values = total_path + '/' + f\n",
    "\n",
    "    max_values = pd.read_pickle(max_values)\n",
    "    \n",
    "    return max_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "max_values = {\n",
    "    'rainint': 0, \n",
    "    'raintot': 0, \n",
    "    'High T': 0, \n",
    "    'Low T': 0, \n",
    "    'Humidity': 0, \n",
    "    'Wind Speed': 0, \n",
    "    'Wind Direction': 0, \n",
    "    'Cloud Cover': 0\n",
    "}\n",
    "\n",
    "for y in years:\n",
    "    pull_weather_data_from_s3(y, weather_directory)\n",
    "\n",
    "    get_max(weather_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rainint': 96.67113881170407, 'raintot': 74.02488986783878, 'High T': 319.74086664358845, 'Low T': 304.52986770355284, 'Humidity': 1.0, 'Wind Speed': 62.57522675889799, 'Wind Direction': 359.0000000000001, 'Cloud Cover': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# take a look\n",
    "print(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to s3\n",
    "save_array_to_s3(s3_client, max_values, bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull from s3\n",
    "max_values = pull_weather_maxes_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rainint': 96.67113881170407,\n",
       " 'raintot': 74.02488986783878,\n",
       " 'High T': 319.74086664358845,\n",
       " 'Low T': 304.52986770355284,\n",
       " 'Humidity': 1.0,\n",
       " 'Wind Speed': 62.57522675889799,\n",
       " 'Wind Direction': 359.0000000000001,\n",
       " 'Cloud Cover': 1.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
