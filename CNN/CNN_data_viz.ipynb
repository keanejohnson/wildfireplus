{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model - Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "# name of directory with fire tif files\n",
    "tif_directory = \"data\"\n",
    "\n",
    "# name of directory with weather data\n",
    "weather_directory = 'weather_data'\n",
    "\n",
    "# name of fire direction file\n",
    "direction_file = 'BBdirectionCA'\n",
    "\n",
    "# name of fire speed file\n",
    "speed_file = 'BBspeedCA'\n",
    "\n",
    "# weather and fire data to include in model\n",
    "rainint = True\n",
    "raintot = False\n",
    "high_t = True\n",
    "low_t = True\n",
    "humidity = True\n",
    "wind_speed = True\n",
    "wind_direction = True\n",
    "cloud_cover = False\n",
    "fire_direction = True\n",
    "fire_speed = True\n",
    "\n",
    "weather_variables = {\n",
    "    'rainint': rainint, \n",
    "    'raintot': raintot, \n",
    "    'High T': high_t, \n",
    "    'Low T': low_t, \n",
    "    'Humidity': humidity, \n",
    "    'Wind Speed': wind_speed, \n",
    "    'Wind Direction': wind_direction, \n",
    "    'Cloud Cover': cloud_cover,\n",
    "    'Fire Direction': fire_direction,\n",
    "    'Fire Speed': fire_speed\n",
    "}\n",
    "\n",
    "weather_vars = []\n",
    "\n",
    "for k, v in weather_variables.items():\n",
    "    if v == True:\n",
    "        weather_vars.append(k)\n",
    "\n",
    "model_3 = None\n",
    "        \n",
    "#####################\n",
    "## HYPERPARAMETERS ##\n",
    "#####################\n",
    "\n",
    "# scale the weather data - yea or nay\n",
    "normalized_weather = True\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# multiplier for amount of zero-labeled data we want to add to dataset\n",
    "labeled_multiplier = 24\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Dataset Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(directory):\n",
    "    '''\n",
    "    Process the dataset in the supplied directory and return matrices of which pixels belong to which fire and \n",
    "    which day of the year the pixel was on fire.\n",
    "    \n",
    "    Args: \n",
    "        - directory: name of directory with tif files\n",
    "    Returns: \n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "\n",
    "    # convert to np array\n",
    "    fire_id = Image.open(tiff_dict['BBfireid'])\n",
    "    fire_id = np.array(fire_id)\n",
    "    fire_id[fire_id == -9999] = 0\n",
    "\n",
    "    fireline = Image.open(tiff_dict['BBfirelineCA'])\n",
    "    fireline = np.array(fireline)\n",
    "    fireline[fireline == -9999] = 0\n",
    "\n",
    "    # get list of unique fire_ids\n",
    "    fire_ids = set()\n",
    "\n",
    "    for row in fire_id:\n",
    "        for val in row:\n",
    "            fire_ids.add(val)\n",
    "\n",
    "    # remove 0 from fire_ids set because it does not denote a fire\n",
    "    fire_ids.remove(0)\n",
    "\n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        id = str(id)\n",
    "        fire_data_dict[id] = {}\n",
    "\n",
    "    for id in fire_ids:\n",
    "        indices = np.where(fire_id == id, 1, 0)\n",
    "        fire_data_dict[str(id)] = indices\n",
    "        \n",
    "    return fire_data_dict, fireline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_matrices(data_dict, fireline):\n",
    "    '''\n",
    "    Create matrices for each fire_id that show were the fire was on a given day during the year.\n",
    "    \n",
    "    Args:\n",
    "        - data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by that fire (0, 1)\n",
    "        - fireline: matrix denoting what day of year that pixel was on fire (1-365)\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    '''\n",
    "    \n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for key, val in data_dict.items():\n",
    "        data = {}\n",
    "                \n",
    "        for y in range(1, 366):\n",
    "            mask = ((fireline == y) & (val == 1))\n",
    "            mask = mask.astype(int)\n",
    "        \n",
    "            if np.sum(mask) > 0:\n",
    "                data[str(y)] = mask\n",
    "        \n",
    "        fire_data_dict[key] = data\n",
    "        \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_pairs(fire_data_dict):\n",
    "    '''\n",
    "    Create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "    the fire was on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - fire_data_dict: a dictionary of the following structure:\n",
    "            {\n",
    "                \"fire_id\": {\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day,\n",
    "                    \"day_of_year\": one-hot encoded 2D array of fire spread on that day\n",
    "                }\n",
    "\n",
    "            }\n",
    "    Returns:\n",
    "        - train_labels: a list of sets where the first value of the set is a one-hot encoded 2D array of fire \n",
    "        spread on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2:\n",
    "        [\n",
    "            (one-hot encoded 2D array of fire spread on that day_1, one-hot encoded 2D array of fire spread on day_2),\n",
    "            (one-hot encoded 2D array of fire spread on that day_2, one-hot encoded 2D array of fire spread on day_3),\n",
    "        ]\n",
    "    '''\n",
    "    \n",
    "    train_labels = []\n",
    "\n",
    "    for key, value in fire_data_dict.items():\n",
    "        burn_matrices = list(value.values())\n",
    "        day_of_year = list(value.keys())\n",
    "        \n",
    "        for index, day in enumerate(burn_matrices):\n",
    "\n",
    "            if index < len(burn_matrices) - 1:\n",
    "                day_1 = burn_matrices[index]\n",
    "                day_2_index = index + 1\n",
    "                day_2 = burn_matrices[day_2_index]\n",
    "                \n",
    "                doy = day_of_year[day_2_index]\n",
    "                \n",
    "                pair = (day_1, day_2)\n",
    "                train_labels.append((doy, pair))\n",
    "\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_tiff(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied tiff file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that tiff file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of tiff file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    tiff_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['BBdayofburnCA'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert tif of interest to np array\n",
    "    fire_data_mat = Image.open(tiff_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Direction'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fire_data_png(directory, file):\n",
    "    '''\n",
    "    Process the fire data in the supplied png file and return a dictionary of key day of year and value a matrix \n",
    "    making up the attribute of that png file\n",
    "\n",
    "    Args:\n",
    "        - directory: name of directory of supplemental data\n",
    "        - file: name of png file of supplemental data to add to model\n",
    "    Returns:\n",
    "        - fire_data_dict: a dictionary where the key is \"fire_id\" and the value is a matrix of pixels \n",
    "        triggered by the attribute of interest\n",
    "    '''\n",
    "    \n",
    "    path = os.path.abspath(directory)\n",
    "\n",
    "    tiff_files = []\n",
    "    png_files = []\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.tif'):\n",
    "            tiff_files.append(path + '/' + f)\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.png'):\n",
    "            png_files.append(path + '/' + f)\n",
    "    \n",
    "    tiff_dict = {}\n",
    "    png_dict = {}\n",
    "\n",
    "    # dictionary of tiff files\n",
    "    for f in tiff_files:\n",
    "        k = f.split('/')[-1].split('.tif')[0]\n",
    "        tiff_dict[k] = f\n",
    "    \n",
    "    for f in png_files:\n",
    "        k = f.split('/')[-1].split('.png')[0]\n",
    "        png_dict[k] = f\n",
    "        \n",
    "    # convert day of burn tif to np array\n",
    "    fire_dob = Image.open(tiff_dict['BBdayofburnCA'])\n",
    "    fire_dob = np.array(fire_dob)\n",
    "    fire_dob[fire_dob == -9999] = 0\n",
    "\n",
    "    # convert png of interest to np array\n",
    "    fire_data_mat = Image.open(png_dict[file])\n",
    "    fire_data_mat = np.array(fire_data_mat)\n",
    "    fire_data_mat[fire_data_mat == -9999] = 0\n",
    "    \n",
    "    # get list of unique days of burn\n",
    "    days_of_burn = list(np.unique(fire_dob))\n",
    "\n",
    "    # remove 0 from days of burn because it does not denote a fire\n",
    "    days_of_burn.remove(0)\n",
    "        \n",
    "    # get dict with key value pairs of fire_id and an empty dict\n",
    "    fire_data_dict = {}\n",
    "\n",
    "    for idx in days_of_burn:\n",
    "        idx = int(idx)\n",
    "        \n",
    "        mask = (fire_dob == idx)        \n",
    "        mask = mask.astype(int)\n",
    "        \n",
    "        values = np.multiply(mask, fire_data_mat)\n",
    "        \n",
    "        idx = str(idx)\n",
    "        fire_data_dict[idx] = {}\n",
    "        fire_data_dict[idx]['Fire Speed'] = values \n",
    "\n",
    "    \n",
    "    return fire_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dicts(dict_1, dict_2):\n",
    "    '''\n",
    "    A helper function to combine the values of two dictionaries that have the same keys.\n",
    "    \n",
    "    Args:\n",
    "        - dict_1: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "        - dict_2: a dictionary of key day of year, and value a dictionary of key fire attribute and value a matrix\n",
    "        denoting where that attribute is triggered\n",
    "    Returns:\n",
    "        - dict_2: combined dictionary of dict_1 and dict_2\n",
    "    '''\n",
    "      \n",
    "    for k, v in dict_1.items():\n",
    "        for att, mat in v.items():\n",
    "            dict_2[k][att] = mat\n",
    "            \n",
    "    return dict_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_dict(directory, normalized_weather, weather_vars, fire_data_dict):\n",
    "    '''\n",
    "    Create a dictionary of weather data from a pickled file\n",
    "    Args:\n",
    "        - directory: path to weather pickle file\n",
    "        - normalized_weather: True/False to scale using max value\n",
    "        - weather_vars: list of weather variables to include in model\n",
    "    Returns:\n",
    "        - weather_data: dictionary of key (day of year) and value (dictionary of key (weather parameter) \n",
    "        and value (matrix of value for each pixel))\n",
    "        - max_values: a list of max values for each weather feature to use to normalize data\n",
    "    '''\n",
    "\n",
    "    path = os.path.abspath(directory)\n",
    "    \n",
    "    weather_file = ''\n",
    "    \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith('.pickle'):\n",
    "            weather_file = path + '/' + f\n",
    "    \n",
    "    weather = pd.read_pickle(weather_file)\n",
    "    \n",
    "    weather_dict = {}\n",
    "    \n",
    "    for k, v in weather.items():\n",
    "        weather_dict[k] = {}\n",
    "        \n",
    "        for att, matrix in v.items():\n",
    "            if att in weather_vars:\n",
    "                \n",
    "                # scale to kelvin\n",
    "                if att in ['High T', 'Low T']:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    mat += 273.15\n",
    "                    weather_dict[k][att] = mat\n",
    "                else:\n",
    "                    mat = np.nan_to_num(matrix)\n",
    "                    weather_dict[k][att] = mat\n",
    "     \n",
    "    weather_data = {}\n",
    "\n",
    "    for k, v in weather_dict.items():\n",
    "        doy = dt.strptime(k, \"%Y-%m-%d\").strftime(\"%j\")\n",
    "        weather_data[doy] = v\n",
    "            \n",
    "    # scale weather data\n",
    "    vals = list(weather_data.values())[0]\n",
    "    weather_atts = list(vals.keys())\n",
    "    max_values = dict.fromkeys(weather_atts, 0)\n",
    "    \n",
    "    if normalized_weather == True:\n",
    "        \n",
    "        for k, v in weather_dict.items():\n",
    "\n",
    "            for weather_att, matrix in v.items():\n",
    "                max_val = matrix.max()\n",
    "                if max_val > max_values[weather_att]:\n",
    "                    max_values[weather_att] = max_val\n",
    "    \n",
    "    return weather_data, max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(max_values, normalized_weather, day_of_year, x, y):\n",
    "    '''\n",
    "    Fetch weather data for the relevant day and pixel.\n",
    "    \n",
    "    Args:\n",
    "        - max_values: list of max_values for each weather features\n",
    "        - normalized_weather: whether the weather data should be normalized - true/false\n",
    "        - day_of_year: day of the year (1-365)\n",
    "        - x: x-coordinate of matrix\n",
    "        - y: y-coordinate of matrix\n",
    "    Returns:\n",
    "        - weather_list: an array of relevant weather data for that pixel\n",
    "    '''\n",
    "    \n",
    "    weather_list = []\n",
    "    \n",
    "    day_weather = weather_data.get(day_of_year)\n",
    "\n",
    "    if day_weather is None:\n",
    "        return None\n",
    "    else:\n",
    "        for k, v in day_weather.items():\n",
    "            if normalized_weather == True:\n",
    "                max_val = max_values.get(k, 1)\n",
    "                \n",
    "                try:\n",
    "                    val = v[x,y]\n",
    "                    value = val/max_val\n",
    "                    \n",
    "                    if math.isnan(value):\n",
    "                        weather_list.append(0)\n",
    "                    else:\n",
    "                        weather_list.append(value)\n",
    "                except IndexError:\n",
    "                    return None\n",
    "            else:\n",
    "                try:\n",
    "                    weather_list.append(v[x,y])\n",
    "                except IndexError:\n",
    "                    return None\n",
    "    \n",
    "    return weather_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Dataset for CNN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, matrix_dim, data_len, side):\n",
    "    '''\n",
    "    Supplement the list produced in `create_labeled_data` with data where there was no data\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - num_pixels: how many \"no-fire\" pixel-matrix pairs we want to return\n",
    "        - side: half the length of the dimension of the outpur matrix\n",
    "    Returns:\n",
    "        - no_fire: a list of sets, where the second value (0, 1) represents whether fire is present for a given \n",
    "        pixel, and the first value is a matrix centered on the second value for the previous day and represents \n",
    "        where the fire was on the previous day\n",
    "    '''\n",
    "        \n",
    "    no_fire = []\n",
    "\n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 0)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "                                    \n",
    "            # control for edge cases where shape doesn't match up - not sure why this is happening\n",
    "            if m.shape == (matrix_dim, matrix_dim):\n",
    "                weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "                if weather_data is not None:\n",
    "                    no_fire.append(((weather_data, m), 0))\n",
    "    \n",
    "    len_no_fire = len(no_fire)\n",
    "    \n",
    "    num_pixels = min(len_no_fire, data_len)\n",
    "    no_fire = random.sample(no_fire, num_pixels)\n",
    "    \n",
    "    return no_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labeled_data(dataset, matrix_dim, labeled_multiplier):\n",
    "    '''\n",
    "    Create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "    whether there was fire in the center pixel on the following day.\n",
    "    \n",
    "    Args:\n",
    "        - dataset: a list of sets where the first value of the set is a one-hot encoded 2D array of fire spread \n",
    "        on day_1 and the second value of the set is a one-hot encoded 2D array of fire spread on day_2\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "        - labeled_multiplier: a hyperparameter for how much \"no-fire\" labeled data to add to the training set\n",
    "    Returns:\n",
    "        - data: a list of sets, where the second value (0, 1) represents whether fire is present for a given pixel, \n",
    "        and the first value is a matrix centered on the second value for the previous day and represents where the \n",
    "        fire was on the previous day\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for (doy, (x, y)) in dataset:    \n",
    "\n",
    "        x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "        y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "\n",
    "        vals = np.where(y == 1)\n",
    "        vals = list(zip(vals[0], vals[1]))\n",
    "\n",
    "        for (xi, yi) in vals:\n",
    "            xi_r = xi + side\n",
    "            xi_l = xi - side\n",
    "            yi_b = yi + side\n",
    "            yi_t = yi - side\n",
    "\n",
    "            m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "                        \n",
    "            weather_data = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "            \n",
    "            if weather_data is not None:\n",
    "                data.append(((weather_data, m), 1))\n",
    "    \n",
    "    data_len = len(data)*labeled_multiplier\n",
    "    \n",
    "    # balance this dataset with values where there is no fire\n",
    "    no_fire = balance_dataset(dataset, matrix_dim, data_len, side)\n",
    "    \n",
    "    # combine and shuffle\n",
    "    data += no_fire    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_for_cnn(data, matrix_dim):\n",
    "    '''\n",
    "    Takes a list of ((weather_data, fire_data), integer) pairs and returns fire data, weather data, and output labels.\n",
    "    \n",
    "    Args:\n",
    "        - data: a list of (matrix, integer) pairs\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - fire: array of input data in matrix_dim X matrix_dim shape\n",
    "        - weather: list of normalized weather weights\n",
    "        - Y: array of output labels (0 or 1)\n",
    "    '''\n",
    "    \n",
    "    fire = []\n",
    "    weather = []\n",
    "    Y = []\n",
    "\n",
    "    for ((w, f), y) in data:\n",
    "        f = np.asarray(f)\n",
    "        fire.append(f)\n",
    "        \n",
    "        w = np.asarray(w)\n",
    "        weather.append(w)\n",
    "        \n",
    "        Y.append(y)\n",
    "\n",
    "    fire = np.asarray(fire)\n",
    "    weather = np.asarray(weather)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    obs = len(fire)\n",
    "    \n",
    "    fire = fire.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "    return fire, weather, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the datat preprocessing pipeline\n",
    "\n",
    "# get fire speed data\n",
    "fire_speed_data_dict = process_fire_data_png(tif_directory, speed_file)\n",
    "\n",
    "# get fire direction data\n",
    "fire_dir_data_dict = process_fire_data_tiff(tif_directory, direction_file)\n",
    "\n",
    "# combine fire speed and fire direction datasets\n",
    "fire_data_dict = combine_dicts(fire_speed_data_dict, fire_dir_data_dict)\n",
    "\n",
    "# create weather dict and combine with fire speed and fire direction\n",
    "weather_data, max_values = create_weather_dict(weather_directory, normalized_weather, weather_vars, fire_data_dict)\n",
    "\n",
    "# return matrices of which pixels belong to which fire and which day of the year the pixel was on fire\n",
    "fire_data_dict, fireline = data_processing(tif_directory)\n",
    "\n",
    "# create matrices for each fire_id that show were the fire was on a given day during the year \n",
    "fire_data_dict = create_one_hot_matrices(fire_data_dict, fireline)\n",
    "\n",
    "# create a list of sets where the first value is where the fire was on a given day and the second value is where\n",
    "# the fire was on the following day\n",
    "small_dataset = create_day_pairs(fire_data_dict)\n",
    "\n",
    "# create a list of sets where the first value is a matrix of pixels on a given day and the second value denotes\n",
    "# whether there was fire in the center pixel on the following day\n",
    "data = create_labeled_data(small_dataset, matrix_dim, labeled_multiplier)\n",
    "\n",
    "# takes data pairs and returns fire data, weather data, and output labels\n",
    "fire, weather, Y = prep_dataset_for_cnn(data, matrix_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually - taken from https://datascience.stackexchange.com/a/45166\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes recall.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - recall: true positives / actual results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes precision.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - precision: true positives / predicted results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - score: f1 score\n",
    "    '''\n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Fire Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1: fire image data with Sequential API\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model_1.add(AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Conv2D(64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(Conv2D(32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Flatten())\n",
    "\n",
    "# Final dense layer \n",
    "model_1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_1.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_1.fit(\n",
    "    x = fire, \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1.predict(fire[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Fire Image Data and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data, weather data, and fire speed/direction data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = fire[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "weather_shape = weather[0].shape\n",
    "weather_inputs = Input(shape = weather_shape)\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "fire_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "fire_2 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(fire_1)\n",
    "fire_3 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(fire_2)\n",
    "fire_4 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_3)\n",
    "fire_5 = Dropout(0.2)(fire_4)\n",
    "fire_6 = Flatten()(fire_5)\n",
    "fire_7 = Dense(64, activation='sigmoid')(fire_6)\n",
    "\n",
    "# Combine the layers\n",
    "concat = concatenate([fire_7, weather_inputs])\n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=[image_inputs, weather_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [fire, weather], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.predict([fire[:10], weather[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, cols = 1, titles = None):\n",
    "    '''\n",
    "    Display a list of images in a single figure with matplotlib. Taken from \n",
    "    https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "    \n",
    "    Args:\n",
    "        - images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "        - cols (Default = 1): Number of columns in figure (number of rows is set to np.ceil(n_images/float(cols))).\n",
    "    \n",
    "        - titles: List of titles corresponding to each image. Must have the same length as titles.\n",
    "    '''\n",
    "\n",
    "    assert((titles is None)or (len(images) == len(titles)))\n",
    "    \n",
    "    n_images = len(images)\n",
    "    \n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        plt.imshow(image, cmap='inferno', interpolation='nearest')\n",
    "        a.set_title(title)\n",
    "    \n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_day(fire_id, doy, model, matrix_dim):\n",
    "    '''\n",
    "    Predicts where fire will be on day \"D + 1\" for a provided fire_id and day of year, using a provided model.\n",
    "    \n",
    "    Args:\n",
    "        - fire_id: ID of fire to be predicted\n",
    "        - doy: Day of year to predict fire for\n",
    "        - model: Model to use for predictions\n",
    "        - matrix_dim: a hyperparameter for the height and width of the matrices fed into the CNN\n",
    "    Returns:\n",
    "        - prediction: numpy matrix of predicted fire probabilities\n",
    "    '''\n",
    "\n",
    "    side = int(matrix_dim/2)\n",
    "    fire_id = str(fire_id)\n",
    "    doy = str(doy)\n",
    "    \n",
    "    try:\n",
    "        true_fire_map = fire_data_dict[fire_id][doy]\n",
    "    except KeyError:\n",
    "        print(\"Not a valid fire_id and day of year combination\")\n",
    "\n",
    "    weather_data_test = weather_data[doy]\n",
    "    small_dataset_test = None\n",
    "\n",
    "    for (day, (x, y)) in small_dataset:\n",
    "        if day == doy:\n",
    "            small_dataset_test = (day, (x, y))\n",
    "\n",
    "    (day, (x, y)) = small_dataset_test\n",
    "        \n",
    "    x = np.pad(x, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "    y = np.pad(y, pad_width=matrix_dim, mode='constant', constant_values=0)\n",
    "    \n",
    "    vals = np.where((y == 1) | (y == 0))\n",
    "    vals = list(zip(vals[0], vals[1]))\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    shape = x.shape\n",
    "    prediction = np.zeros(shape)\n",
    "    \n",
    "    for (xi, yi) in vals:\n",
    "        point = (xi, yi)\n",
    "        \n",
    "        xi_r = xi + side\n",
    "        xi_l = xi - side\n",
    "        yi_b = yi + side\n",
    "        yi_t = yi - side\n",
    "\n",
    "        m = x[xi_l:xi_r, yi_t:yi_b]\n",
    "        \n",
    "        weather = fetch_weather_data(max_values, normalized_weather, doy, xi, yi)\n",
    "\n",
    "        y_label = y[xi, yi]\n",
    "        \n",
    "        if (weather is not None) and (m.shape == (matrix_dim, matrix_dim)):\n",
    "            values.append((point, y_label, weather, m))\n",
    "    \n",
    "    \n",
    "    for (point, y_label, w, f) in values:        \n",
    "        fire = []\n",
    "        weather = []\n",
    "        Y = []\n",
    "\n",
    "        fire.append(np.asarray(f))\n",
    "        weather.append(np.asarray(w))\n",
    "        Y.append(y_label)\n",
    "\n",
    "        fire = np.asarray(fire)\n",
    "        weather = np.asarray(weather)\n",
    "        Y = np.asarray(Y)\n",
    "        \n",
    "        obs = len(fire)\n",
    "        fire = fire.reshape(obs, matrix_dim, matrix_dim, 1)\n",
    "\n",
    "        if model == model_1:\n",
    "            val = model.predict(fire)\n",
    "        elif model in (model_2, model_3):\n",
    "            val = model.predict([fire, weather])\n",
    "            \n",
    "        prediction[point] = val\n",
    "    \n",
    "    x_start = matrix_dim\n",
    "    x_end = 456 + matrix_dim\n",
    "    y_start = matrix_dim\n",
    "    y_end = 470 + matrix_dim\n",
    "    \n",
    "    prediction = prediction[y_start:y_end, x_start:x_end]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Day of Fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a day of fire to test\n",
    "a = fire_data_dict['140']['209']\n",
    "\n",
    "# focus more closely on the fire\n",
    "b = a[0:200, 0:200]\n",
    "\n",
    "# predict fire location for that day using model 1\n",
    "c = predict_day('140', '209', model_1, matrix_dim)\n",
    "\n",
    "# focus more closely on that fire\n",
    "d = c[0:200, 0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "images_1 = [a, c, b, d]\n",
    "titles_1 = [\"True Values\", \"Predicted Values (no Weather)\", \"True Values Zoomed\", \"Predicted Values Zoomed (no Weather)\"]\n",
    "show_images(images_1, titles=titles_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outline of fire\n",
    "k = np.rint(d)\n",
    "k = np.diff(k)\n",
    "k = np.abs(k)\n",
    "plt.imshow(k, cmap='inferno', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outline of fire\n",
    "kk = np.where(d < 0.9, 0, 1)\n",
    "kk = np.diff(kk)\n",
    "kk = np.abs(kk)\n",
    "plt.imshow(kk, cmap='inferno', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict fire locationf or that day using model 2\n",
    "e = predict_day('140', '209', model_2, matrix_dim)\n",
    "\n",
    "# focus more closely on prediction\n",
    "f = e[0:200, 0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "images_2 = [a, e, b, f]\n",
    "titles_2 = [\"True Values\", \"Predicted Values (with Weather)\", \"True Values Zoomed\", \"Predicted Values Zoomed (with Weather)\"]\n",
    "show_images(images_2, titles=titles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get outline of fire\n",
    "\n",
    "# zoomed\n",
    "j = np.where(f < 0.9, 0, 1)\n",
    "j = np.diff(j)\n",
    "j = np.abs(j)\n",
    "plt.imshow(j, cmap='inferno', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "# not zoomed\n",
    "k = np.where(e < 0.9, 0, 1)\n",
    "k = np.diff(k)\n",
    "k = np.abs(k)\n",
    "plt.imshow(k, cmap='inferno', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with actual\n",
    "\n",
    "extent = np.min(b), np.max(b), np.min(f), np.max(f)\n",
    "\n",
    "fig = plt.figure(frameon=False)\n",
    "im1 = plt.imshow(b, cmap='gray', interpolation='bilinear', extent=extent)\n",
    "im2 = plt.imshow(f, cmap='inferno', interpolation='nearest', extent=extent, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with previous days of fire\n",
    "\n",
    "z = fire_data_dict['140']['203'][0:200, 0:200]\n",
    "y = fire_data_dict['140']['204'][0:200, 0:200]\n",
    "x = fire_data_dict['140']['205'][0:200, 0:200]\n",
    "v = fire_data_dict['140']['206'][0:200, 0:200]\n",
    "u = fire_data_dict['140']['207'][0:200, 0:200]\n",
    "t = fire_data_dict['140']['208'][0:200, 0:200]\n",
    "\n",
    "zz = 0\n",
    "zz = np.add(z, y)\n",
    "zz = np.add(zz, x)\n",
    "zz = np.add(zz, v)\n",
    "zz = np.add(zz, u)\n",
    "zz = np.add(zz, t)\n",
    "\n",
    "\n",
    "extent = np.min(zz), np.max(zz), np.min(f), np.max(f)\n",
    "\n",
    "fig2 = plt.figure(frameon=False)\n",
    "fig2.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to Day D - 1\")\n",
    "im_203 = plt.imshow(zz, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_208 = plt.imshow(f, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "yy = np.add(zz, b)\n",
    "fig3 = plt.figure(frameon=False)\n",
    "im_act = plt.imshow(yy, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_pred = plt.imshow(f, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "fig3.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to and Including Day D\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: More Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_from_s3(s3_client, bucket_name, key_name):\n",
    "    '''\n",
    "    Pulls pre-processed data from S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - bucket_name: name of bucket on s3 to pull data from\n",
    "        - key_name: directory/file_name to pull data from\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, key_name, array_data)\n",
    "    \n",
    "    array_data.seek(0)\n",
    "    array = pickle.load(array_data)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# load model from s3\n",
    "new_config = pull_data_from_s3(s3_client, bucket_name, 'models/model_config.pickle')\n",
    "new_weights = pull_data_from_s3(s3_client, bucket_name, 'models/model_weights.pickle')\n",
    "\n",
    "model_3 = keras.Model.from_config(new_config)\n",
    "model_3.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict fire locationf or that day using model 2\n",
    "l = predict_day('140', '209', model_3, matrix_dim)\n",
    "\n",
    "# focus more closely on prediction\n",
    "m = l[0:200, 0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "m = l[0:200, 0:200]\n",
    "m = np.where(m < 0.75, 0, 1)\n",
    "images_3 = [a, l, b, m]\n",
    "titles_3 = [\"True Values\", \"Predicted Values (with Weather)\", \"True Values Zoomed\", \"Predicted Values Zoomed (with Weather)\"]\n",
    "show_images(images_3, titles=titles_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outline of fire\n",
    "\n",
    "# zoomed\n",
    "n = np.where(m < 0.9, 0, 1)\n",
    "n = np.diff(n)\n",
    "n = np.abs(n)\n",
    "plt.imshow(n, cmap='inferno', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "# not zoomed\n",
    "o = np.where(l < 0.9, 0, 1)\n",
    "o = np.diff(o)\n",
    "o = np.abs(o)\n",
    "plt.imshow(o, cmap='inferno', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with actual\n",
    "\n",
    "extent = np.min(b), np.max(b), np.min(m), np.max(m)\n",
    "\n",
    "fig = plt.figure(frameon=False)\n",
    "im1 = plt.imshow(b, cmap='gray', interpolation='bilinear', extent=extent)\n",
    "im2 = plt.imshow(m, cmap='inferno', interpolation='nearest', extent=extent, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with previous days of fire\n",
    "\n",
    "z = fire_data_dict['140']['203'][0:200, 0:200]\n",
    "y = fire_data_dict['140']['204'][0:200, 0:200]\n",
    "x = fire_data_dict['140']['205'][0:200, 0:200]\n",
    "v = fire_data_dict['140']['206'][0:200, 0:200]\n",
    "u = fire_data_dict['140']['207'][0:200, 0:200]\n",
    "t = fire_data_dict['140']['208'][0:200, 0:200]\n",
    "\n",
    "zz = 0\n",
    "zz = np.add(z, y)\n",
    "zz = np.add(zz, x)\n",
    "zz = np.add(zz, v)\n",
    "zz = np.add(zz, u)\n",
    "zz = np.add(zz, t)\n",
    "\n",
    "\n",
    "extent = np.min(zz), np.max(zz), np.min(m), np.max(m)\n",
    "\n",
    "fig2 = plt.figure(frameon=False)\n",
    "fig2.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to Day D - 1\")\n",
    "im_203 = plt.imshow(zz, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_208 = plt.imshow(m, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "yy = np.add(zz, b)\n",
    "fig3 = plt.figure(frameon=False)\n",
    "im_act = plt.imshow(yy, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_pred = plt.imshow(m, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "fig3.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to and Including Day D\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict fire locationf or that day using model 2\n",
    "l = predict_day('140', '210', model_3, matrix_dim)\n",
    "\n",
    "# focus more closely on prediction\n",
    "m = l[0:200, 0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "m = l[0:200, 0:200]\n",
    "\n",
    "# m = np.where(m < 0.75, 0, 1)\n",
    "images_3 = [a, l, b, m]\n",
    "titles_3 = [\"True Values\", \"Predicted Values (with Weather)\", \"True Values Zoomed\", \"Predicted Values Zoomed (with Weather)\"]\n",
    "show_images(images_3, titles=titles_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outline of fire\n",
    "\n",
    "# zoomed\n",
    "n = np.rint(m)\n",
    "n = np.diff(n)\n",
    "n = np.abs(n)\n",
    "plt.imshow(n, cmap='inferno', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "# not zoomed\n",
    "o = np.rint(m)\n",
    "o = np.diff(o)\n",
    "o = np.abs(o)\n",
    "plt.imshow(o, cmap='inferno', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with actual\n",
    "\n",
    "extent = np.min(b), np.max(b), np.min(m), np.max(m)\n",
    "\n",
    "fig = plt.figure(frameon=False)\n",
    "im1 = plt.imshow(b, cmap='gray', interpolation='bilinear', extent=extent)\n",
    "im2 = plt.imshow(m, cmap='inferno', interpolation='nearest', extent=extent, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay prediction with previous days of fire\n",
    "\n",
    "z = fire_data_dict['140']['203'][0:200, 0:200]\n",
    "y = fire_data_dict['140']['204'][0:200, 0:200]\n",
    "x = fire_data_dict['140']['205'][0:200, 0:200]\n",
    "v = fire_data_dict['140']['206'][0:200, 0:200]\n",
    "u = fire_data_dict['140']['207'][0:200, 0:200]\n",
    "t = fire_data_dict['140']['208'][0:200, 0:200]\n",
    "s = fire_data_dict['140']['209'][0:200, 0:200]\n",
    "\n",
    "zz = 0\n",
    "zz = np.add(z, y)\n",
    "zz = np.add(zz, x)\n",
    "zz = np.add(zz, v)\n",
    "zz = np.add(zz, u)\n",
    "zz = np.add(zz, t)\n",
    "zz = np.add(zz, s)\n",
    "\n",
    "\n",
    "extent = np.min(zz), np.max(zz), np.min(m), np.max(m)\n",
    "\n",
    "fig2 = plt.figure(frameon=False)\n",
    "fig2.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to Day D - 1\")\n",
    "im_203 = plt.imshow(zz, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_208 = plt.imshow(m, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "yy = np.add(zz, b)\n",
    "fig3 = plt.figure(frameon=False)\n",
    "im_act = plt.imshow(yy, cmap='Blues', interpolation='bilinear', extent=extent)\n",
    "im_pred = plt.imshow(m, cmap='Reds', interpolation='nearest', extent=extent, alpha=0.5)\n",
    "fig3.suptitle(\"Prediction of Day D Overlayed with Fire Extent up to and Including Day D\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
