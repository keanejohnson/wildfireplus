{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model - Previous Fire Data and Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import boto3\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 config\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# CNN config\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_from_s3(s3_client, bucket_name, key_name):\n",
    "    '''\n",
    "    Pulls pre-processed data from S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - bucket_name: name of bucket on s3 to pull data from\n",
    "        - key_name: directory/file_name to pull data from\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, key_name, array_data)\n",
    "    \n",
    "    array_data.seek(0)\n",
    "    array = pickle.load(array_data)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_key_name = 'test/fire_2016.pickle'\n",
    "weather_key_name = 'test/weather_2016.pickle'\n",
    "label_key_name = 'test/label_2016.pickle'\n",
    "\n",
    "fire = pull_data_from_s3(s3_client, bucket_name, fire_key_name)\n",
    "weather = pull_data_from_s3(s3_client, bucket_name, weather_key_name)\n",
    "Y = pull_data_from_s3(s3_client, bucket_name, label_key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually - taken from https://datascience.stackexchange.com/a/45166\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes recall.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - recall: true positives / actual results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes precision.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - precision: true positives / predicted results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - score: f1 score\n",
    "    '''\n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data, weather data, and fire speed/direction data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = fire[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "weather_shape = weather[0].shape\n",
    "weather_inputs = Input(shape = weather_shape)\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "fire_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "fire_2 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(fire_1)\n",
    "fire_3 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(fire_2)\n",
    "fire_4 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_3)\n",
    "fire_5 = Dropout(0.2)(fire_4)\n",
    "fire_6 = Flatten()(fire_5)\n",
    "fire_7 = Dense(64, activation='sigmoid')(fire_6)\n",
    "\n",
    "# Combine the layers\n",
    "concat = concatenate([fire_7, weather_inputs])\n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=[image_inputs, weather_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 156 ms, sys: 0 ns, total: 156 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5409 samples, validate on 1353 samples\n",
      "Epoch 1/10\n",
      "5409/5409 [==============================] - 7s 1ms/step - loss: 0.7074 - accuracy: 0.4981 - f1_score: 0.4063 - auc: 0.4695 - val_loss: 0.7007 - val_accuracy: 0.5137 - val_f1_score: 0.0000e+00 - val_auc: 0.4961\n",
      "Epoch 2/10\n",
      "5409/5409 [==============================] - 5s 910us/step - loss: 0.6035 - accuracy: 0.7029 - f1_score: 0.5884 - auc: 0.5515 - val_loss: 0.3852 - val_accuracy: 0.8322 - val_f1_score: 0.7824 - val_auc: 0.6581\n",
      "Epoch 3/10\n",
      "5409/5409 [==============================] - 5s 866us/step - loss: 0.2975 - accuracy: 0.8909 - f1_score: 0.8716 - auc: 0.7400 - val_loss: 0.2039 - val_accuracy: 0.9298 - val_f1_score: 0.9191 - val_auc: 0.8017\n",
      "Epoch 4/10\n",
      "5409/5409 [==============================] - 5s 926us/step - loss: 0.2030 - accuracy: 0.9338 - f1_score: 0.9296 - auc: 0.8407 - val_loss: 0.1553 - val_accuracy: 0.9342 - val_f1_score: 0.9243 - val_auc: 0.8686\n",
      "Epoch 5/10\n",
      "5409/5409 [==============================] - 5s 882us/step - loss: 0.1628 - accuracy: 0.9486 - f1_score: 0.9390 - auc: 0.8879 - val_loss: 0.1123 - val_accuracy: 0.9549 - val_f1_score: 0.9488 - val_auc: 0.9040\n",
      "Epoch 6/10\n",
      "5409/5409 [==============================] - 5s 964us/step - loss: 0.1390 - accuracy: 0.9584 - f1_score: 0.9498 - auc: 0.9159 - val_loss: 0.0894 - val_accuracy: 0.9638 - val_f1_score: 0.9610 - val_auc: 0.9256\n",
      "Epoch 7/10\n",
      "5409/5409 [==============================] - 5s 898us/step - loss: 0.1225 - accuracy: 0.9632 - f1_score: 0.9563 - auc: 0.9331 - val_loss: 0.0822 - val_accuracy: 0.9852 - val_f1_score: 0.9838 - val_auc: 0.9399\n",
      "Epoch 8/10\n",
      "5409/5409 [==============================] - 5s 870us/step - loss: 0.1055 - accuracy: 0.9700 - f1_score: 0.9622 - auc: 0.9454 - val_loss: 0.1346 - val_accuracy: 0.9527 - val_f1_score: 0.9461 - val_auc: 0.9498\n",
      "Epoch 9/10\n",
      "5409/5409 [==============================] - 5s 962us/step - loss: 0.1049 - accuracy: 0.9713 - f1_score: 0.9698 - auc: 0.9531 - val_loss: 0.0544 - val_accuracy: 0.9845 - val_f1_score: 0.9828 - val_auc: 0.9566\n",
      "Epoch 10/10\n",
      "5409/5409 [==============================] - 5s 977us/step - loss: 0.0876 - accuracy: 0.9763 - f1_score: 0.9755 - auc: 0.9597 - val_loss: 0.0637 - val_accuracy: 0.9749 - val_f1_score: 0.9730 - val_auc: 0.9624\n",
      "CPU times: user 1min 54s, sys: 1min 27s, total: 3min 21s\n",
      "Wall time: 52.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1e12e24fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [fire, weather], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CNN to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'F3469A306283E0F5',\n",
       "  'HostId': 'FEVIyr4emxbviWUvAcW6SBUb7yJsPRMn0KZfg2I/p3BMt9F+3+1dEPQVKexCzxCfDGQ5yte44Gw=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'FEVIyr4emxbviWUvAcW6SBUb7yJsPRMn0KZfg2I/p3BMt9F+3+1dEPQVKexCzxCfDGQ5yte44Gw=',\n",
       "   'x-amz-request-id': 'F3469A306283E0F5',\n",
       "   'date': 'Sat, 04 Apr 2020 21:57:19 GMT',\n",
       "   'etag': '\"a9002150b4b519d41a00a3afb234fcd5\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"a9002150b4b519d41a00a3afb234fcd5\"'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = model_2.to_json()\n",
    "s3_client.put_object(Body=saved_model, Bucket=bucket_name, Key='models/model_2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket_name, 'models/model_2.json', 'model.json')\n",
    "\n",
    "with open('model.json', 'r') as model_file:\n",
    "    loaded_model = model_file.read()\n",
    "\n",
    "model = model_from_json(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
