{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model - Previous Fire Data and Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes data from S3, trains a CNN model using Keras and Tensorflow, and saves the model to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import boto3\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 config\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# CNN config\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_from_s3(s3_client, bucket_name, key_name):\n",
    "    '''\n",
    "    Pulls pre-processed data from S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - bucket_name: name of bucket on s3 to pull data from\n",
    "        - key_name: directory/file_name to pull data from\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, key_name, array_data)\n",
    "    \n",
    "    array_data.seek(0)\n",
    "    array = pickle.load(array_data)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Starting data preprocessing for year:  2003\n",
      "2020-04-10 18:50:24.198759\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2004\n",
      "2020-04-10 18:50:26.648937\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2005\n",
      "2020-04-10 18:50:29.383776\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2006\n",
      "2020-04-10 18:50:30.326074\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2007\n",
      "2020-04-10 18:50:32.172811\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2008\n",
      "2020-04-10 18:50:33.752327\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2009\n",
      "2020-04-10 18:50:41.150656\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2010\n",
      "2020-04-10 18:50:42.771985\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2011\n",
      "2020-04-10 18:50:43.602710\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2012\n",
      "2020-04-10 18:50:44.824663\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2013\n",
      "2020-04-10 18:50:45.272620\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2014\n",
      "2020-04-10 18:50:52.656651\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2015\n",
      "2020-04-10 18:50:55.640387\n",
      "*****************************************\n",
      "*****************************************\n",
      "Starting data preprocessing for year:  2016\n",
      "2020-04-10 18:51:01.972761\n",
      "*****************************************\n"
     ]
    }
   ],
   "source": [
    "years = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "fire = []\n",
    "weather = []\n",
    "Y = []\n",
    "\n",
    "for y in years:\n",
    "    print('*****************************************')\n",
    "    print('Starting data preprocessing for year: ', y)\n",
    "    time = dt.now()\n",
    "    print (time)\n",
    "    print('*****************************************')\n",
    "    \n",
    "    fire_key_name = \"input_fire/fire_{}.pickle\".format(str(y))\n",
    "    weather_key_name = \"input_weather/weather_{}.pickle\".format(str(y))\n",
    "    label_key_name = \"labels/label_{}.pickle\".format(str(y))\n",
    "    \n",
    "    fire_data = pull_data_from_s3(s3_client, bucket_name, fire_key_name)\n",
    "    weather_data = pull_data_from_s3(s3_client, bucket_name, weather_key_name)\n",
    "    labels = pull_data_from_s3(s3_client, bucket_name, label_key_name)\n",
    "    \n",
    "    fire.append(fire_data)\n",
    "    weather.append(weather_data)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656500, 32, 32, 1)\n",
      "(656500, 8)\n",
      "(656500,)\n"
     ]
    }
   ],
   "source": [
    "fire = np.concatenate(fire)\n",
    "weather = np.concatenate(weather)\n",
    "Y = np.concatenate(Y)\n",
    "\n",
    "print(fire.shape)\n",
    "print(weather.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually - taken from https://datascience.stackexchange.com/a/45166\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes recall.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - recall: true positives / actual results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes precision.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - precision: true positives / predicted results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - score: f1 score\n",
    "    '''\n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data, weather data, and fire speed/direction data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = fire[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "weather_shape = weather[0].shape\n",
    "weather_inputs = Input(shape = weather_shape)\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "fire_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "\n",
    "fire_2 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(fire_1)\n",
    "fire_3 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_2)\n",
    "fire_4 = Dropout(0.2)(fire_3)\n",
    "\n",
    "fire_5 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(fire_4)\n",
    "fire_6 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_5)\n",
    "fire_7 = Dropout(0.2)(fire_6)\n",
    "\n",
    "fire_8 = Flatten()(fire_7)\n",
    "fire_9 = Dense(128, activation='sigmoid')(fire_8)\n",
    "\n",
    "# Combine the layers\n",
    "concat = concatenate([fire_9, weather_inputs])\n",
    "\n",
    "# Final dense layer \n",
    "predictions = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "# Define the model\n",
    "model_2 = Model(inputs=[image_inputs, weather_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 525200 samples, validate on 131300 samples\n",
      "Epoch 1/10\n",
      "525200/525200 [==============================] - 271s 516us/step - loss: 0.0306 - accuracy: 0.9929 - f1_score: 0.6144 - auc_1: 0.9179 - val_loss: 0.0088 - val_accuracy: 0.9984 - val_f1_score: 0.7026 - val_auc_1: 0.9822\n",
      "Epoch 2/10\n",
      "525200/525200 [==============================] - 266s 507us/step - loss: 0.0094 - accuracy: 0.9982 - f1_score: 0.7023 - auc_1: 0.9868 - val_loss: 0.0083 - val_accuracy: 0.9986 - val_f1_score: 0.7065 - val_auc_1: 0.9886\n",
      "Epoch 3/10\n",
      "525200/525200 [==============================] - 265s 505us/step - loss: 0.0080 - accuracy: 0.9984 - f1_score: 0.7095 - auc_1: 0.9899 - val_loss: 0.0084 - val_accuracy: 0.9986 - val_f1_score: 0.7076 - val_auc_1: 0.9904\n",
      "Epoch 4/10\n",
      "525200/525200 [==============================] - 266s 506us/step - loss: 0.0069 - accuracy: 0.9987 - f1_score: 0.7170 - auc_1: 0.9910 - val_loss: 0.0080 - val_accuracy: 0.9985 - val_f1_score: 0.7077 - val_auc_1: 0.9913\n",
      "Epoch 5/10\n",
      "525200/525200 [==============================] - 266s 506us/step - loss: 0.0065 - accuracy: 0.9987 - f1_score: 0.7126 - auc_1: 0.9917 - val_loss: 0.0078 - val_accuracy: 0.9986 - val_f1_score: 0.7078 - val_auc_1: 0.9919\n",
      "Epoch 6/10\n",
      "525200/525200 [==============================] - 261s 498us/step - loss: 0.0063 - accuracy: 0.9988 - f1_score: 0.7177 - auc_1: 0.9921 - val_loss: 0.0085 - val_accuracy: 0.9984 - val_f1_score: 0.7077 - val_auc_1: 0.9922\n",
      "Epoch 7/10\n",
      "525200/525200 [==============================] - 273s 519us/step - loss: 0.0062 - accuracy: 0.9988 - f1_score: 0.7135 - auc_1: 0.9922 - val_loss: 0.0077 - val_accuracy: 0.9985 - val_f1_score: 0.7073 - val_auc_1: 0.9926\n",
      "Epoch 8/10\n",
      "525200/525200 [==============================] - 261s 498us/step - loss: 0.0060 - accuracy: 0.9988 - f1_score: 0.7181 - auc_1: 0.9929 - val_loss: 0.0080 - val_accuracy: 0.9985 - val_f1_score: 0.7062 - val_auc_1: 0.9928\n",
      "Epoch 9/10\n",
      "525200/525200 [==============================] - 265s 504us/step - loss: 0.0059 - accuracy: 0.9988 - f1_score: 0.7148 - auc_1: 0.9930 - val_loss: 0.0087 - val_accuracy: 0.9984 - val_f1_score: 0.7072 - val_auc_1: 0.9929\n",
      "Epoch 10/10\n",
      "525200/525200 [==============================] - 265s 506us/step - loss: 0.0059 - accuracy: 0.9988 - f1_score: 0.7118 - auc_1: 0.9931 - val_loss: 0.0079 - val_accuracy: 0.9984 - val_f1_score: 0.7072 - val_auc_1: 0.9931\n",
      "CPU times: user 1h 35min 27s, sys: 1h 19min 53s, total: 2h 55min 21s\n",
      "Wall time: 44min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4597296eb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "model_2.fit(\n",
    "    x = [fire, weather], \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CNN to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_s3(s3_client, array, bucket_name, key_name):\n",
    "    '''\n",
    "    Uploads pre-processed data to S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - array: numpy array to save to s3\n",
    "        - bucket_name: name of bucket on s3 to save array to\n",
    "        - key_name: directory/file_name to save data to\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    pickle.dump(array, array_data)\n",
    "    array_data.seek(0)\n",
    "    \n",
    "    s3_client.upload_fileobj(array_data, bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model config and model weights\n",
    "\n",
    "config = model_2.get_config()\n",
    "weights = model_2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model config and model weights to s3\n",
    "\n",
    "save_array_to_s3(s3_client, config, bucket_name, 'models/model_config.pickle')\n",
    "save_array_to_s3(s3_client, weights, bucket_name, 'models/model_weights.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = pull_data_from_s3(s3_client, bucket_name, 'models/model_config.pickle')\n",
    "new_weights = pull_data_from_s3(s3_client, bucket_name, 'models/model_weights.pickle')\n",
    "\n",
    "\n",
    "new_model = keras.Model.from_config(new_config)\n",
    "new_model.set_weights(new_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
