{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model - Previous Fire Data and Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes data from S3, trains a CNN model using Keras and Tensorflow, and saves the model to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import boto3\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 config\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'hotzone'\n",
    "\n",
    "# CNN config\n",
    "\n",
    "# the desired height and width (in pixels) of the matrix to feed into the CNN\n",
    "# 1 pixel side = 500 meters = 0.310686 miles\n",
    "matrix_dim = 32\n",
    "\n",
    "# test size for train/test split\n",
    "test_size = 0.2\n",
    "\n",
    "# training epochs\n",
    "epoc = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_from_s3(s3_client, bucket_name, key_name):\n",
    "    '''\n",
    "    Pulls pre-processed data from S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - bucket_name: name of bucket on s3 to pull data from\n",
    "        - key_name: directory/file_name to pull data from\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name, key_name, array_data)\n",
    "    \n",
    "    array_data.seek(0)\n",
    "    array = pickle.load(array_data)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "fire = []\n",
    "Y = []\n",
    "\n",
    "for y in years:\n",
    "    fire_key_name = \"input_fire/fire_{}.pickle\".format(str(y))\n",
    "    label_key_name = \"labels/label_{}.pickle\".format(str(y))\n",
    "    \n",
    "    fire_data = pull_data_from_s3(s3_client, bucket_name, fire_key_name)\n",
    "    labels = pull_data_from_s3(s3_client, bucket_name, label_key_name)\n",
    "    \n",
    "    fire.append(fire_data)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145155, 32, 32, 1)\n",
      "(145155,)\n"
     ]
    }
   ],
   "source": [
    "fire = np.concatenate(fire)\n",
    "Y = np.concatenate(Y)\n",
    "\n",
    "print(fire.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Conv1D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 score manually - taken from https://datascience.stackexchange.com/a/45166\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes recall.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - recall: true positives / actual results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_pos / (possible_pos + K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    '''\n",
    "    Computes precision.\n",
    "    \n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - precision: true positives / predicted results\n",
    "    '''\n",
    "    \n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    '''\n",
    "    Args:\n",
    "        - y_true: true values of target variable.\n",
    "        - y_pred: predicted values of target variable.\n",
    "    Returns:\n",
    "        - score: f1 score\n",
    "    '''\n",
    "    \n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    score = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_2: image data, weather data, and fire speed/direction data with functional API\n",
    "\n",
    "# Define image inputs shape\n",
    "image_shape = fire[0].shape\n",
    "image_inputs = Input(shape = image_shape)\n",
    "\n",
    "# Define weather inputs shape\n",
    "# weather_shape = weather[0].shape\n",
    "# weather_inputs = Input(shape = weather_shape)\n",
    "\n",
    "# Add layers for fire image interpretation\n",
    "fire_1 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid')(image_inputs)\n",
    "\n",
    "fire_2 = Conv2D(32, kernel_size=(3, 3), activation='sigmoid')(fire_1)\n",
    "fire_3 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_2)\n",
    "fire_4 = Dropout(0.2)(fire_3)\n",
    "\n",
    "fire_5 = Conv2D(64, kernel_size=(3, 3), activation='sigmoid')(fire_4)\n",
    "fire_6 = MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(fire_5)\n",
    "fire_7 = Dropout(0.2)(fire_6)\n",
    "\n",
    "fire_8 = Flatten()(fire_7)\n",
    "fire_9 = Dense(128, activation='sigmoid')(fire_8)\n",
    "\n",
    "# Combine the layers\n",
    "# concat = concatenate([fire_9, weather_inputs])\n",
    "\n",
    "# Final dense layer \n",
    "# predictions = Dense(1, activation='sigmoid')(concat)\n",
    "predictions = Dense(1, activation='sigmoid')(fire_9)\n",
    "\n",
    "# Define the model\n",
    "# model_2 = Model(inputs=[image_inputs, weather_inputs], outputs=predictions)\n",
    "model_2 = Model(inputs=image_inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 0 ns, total: 160 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compile the model\n",
    "model_2.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', f1_score, tf.keras.metrics.AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116124 samples, validate on 29031 samples\n",
      "Epoch 1/10\n",
      "116124/116124 [==============================] - 60s 514us/step - loss: 0.1680 - accuracy: 0.9415 - f1_score: 0.7730 - auc: 0.8462 - val_loss: 0.0528 - val_accuracy: 0.9904 - val_f1_score: 0.9712 - val_auc: 0.9638\n",
      "Epoch 2/10\n",
      "116124/116124 [==============================] - 59s 507us/step - loss: 0.0446 - accuracy: 0.9897 - f1_score: 0.9702 - auc: 0.9773 - val_loss: 0.0404 - val_accuracy: 0.9926 - val_f1_score: 0.9779 - val_auc: 0.9831\n",
      "Epoch 3/10\n",
      "116124/116124 [==============================] - 56s 482us/step - loss: 0.0289 - accuracy: 0.9943 - f1_score: 0.9838 - auc: 0.9865 - val_loss: 0.0363 - val_accuracy: 0.9932 - val_f1_score: 0.9800 - val_auc: 0.9883\n",
      "Epoch 4/10\n",
      "116124/116124 [==============================] - 56s 483us/step - loss: 0.0237 - accuracy: 0.9954 - f1_score: 0.9862 - auc: 0.9897 - val_loss: 0.0351 - val_accuracy: 0.9936 - val_f1_score: 0.9810 - val_auc: 0.9905\n",
      "Epoch 5/10\n",
      "116124/116124 [==============================] - 57s 492us/step - loss: 0.0213 - accuracy: 0.9960 - f1_score: 0.9886 - auc: 0.9912 - val_loss: 0.0334 - val_accuracy: 0.9938 - val_f1_score: 0.9815 - val_auc: 0.9916\n",
      "Epoch 6/10\n",
      "116124/116124 [==============================] - 58s 498us/step - loss: 0.0207 - accuracy: 0.9963 - f1_score: 0.9888 - auc: 0.9921 - val_loss: 0.0307 - val_accuracy: 0.9946 - val_f1_score: 0.9832 - val_auc: 0.9923\n",
      "Epoch 7/10\n",
      "116124/116124 [==============================] - 59s 509us/step - loss: 0.0202 - accuracy: 0.9965 - f1_score: 0.9894 - auc: 0.9926 - val_loss: 0.0324 - val_accuracy: 0.9941 - val_f1_score: 0.9823 - val_auc: 0.9927\n",
      "Epoch 8/10\n",
      "116124/116124 [==============================] - 57s 487us/step - loss: 0.0199 - accuracy: 0.9967 - f1_score: 0.9897 - auc: 0.9930 - val_loss: 0.0329 - val_accuracy: 0.9941 - val_f1_score: 0.9822 - val_auc: 0.9930\n",
      "Epoch 9/10\n",
      "116124/116124 [==============================] - 58s 502us/step - loss: 0.0197 - accuracy: 0.9968 - f1_score: 0.9907 - auc: 0.9932 - val_loss: 0.0333 - val_accuracy: 0.9944 - val_f1_score: 0.9827 - val_auc: 0.9932\n",
      "Epoch 10/10\n",
      "116124/116124 [==============================] - 55s 474us/step - loss: 0.0190 - accuracy: 0.9969 - f1_score: 0.9906 - auc: 0.9934 - val_loss: 0.0321 - val_accuracy: 0.9945 - val_f1_score: 0.9829 - val_auc: 0.9934\n",
      "CPU times: user 20min 35s, sys: 17min 15s, total: 37min 51s\n",
      "Wall time: 9min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f541c0adf98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "# model_2.fit(\n",
    "#     x = [fire, weather], \n",
    "#     y = Y,\n",
    "#     validation_split = test_size, \n",
    "#     epochs=epoc\n",
    "# )\n",
    "\n",
    "model_2.fit(\n",
    "    x = fire, \n",
    "    y = Y,\n",
    "    validation_split = test_size, \n",
    "    epochs=epoc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CNN to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_s3(s3_client, array, bucket_name, key_name):\n",
    "    '''\n",
    "    Uploads pre-processed data to S3.\n",
    "\n",
    "    Args:\n",
    "        - s3_client: boto3 s3 client\n",
    "        - array: numpy array to save to s3\n",
    "        - bucket_name: name of bucket on s3 to save array to\n",
    "        - key_name: directory/file_name to save data to\n",
    "    Returns:\n",
    "        - Nothing\n",
    "    \n",
    "    https://stackoverflow.com/questions/48049557/how-to-write-npy-file-to-s3-directly\n",
    "    '''\n",
    "    \n",
    "    array_data = io.BytesIO()\n",
    "    pickle.dump(array, array_data)\n",
    "    array_data.seek(0)\n",
    "    \n",
    "    s3_client.upload_fileobj(array_data, bucket_name, key_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model config and model weights\n",
    "\n",
    "config = model_2.get_config()\n",
    "weights = model_2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model config and model weights to s3\n",
    "\n",
    "save_array_to_s3(s3_client, config, bucket_name, 'models/model_config.pickle')\n",
    "save_array_to_s3(s3_client, weights, bucket_name, 'models/model_weights.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = pull_data_from_s3(s3_client, bucket_name, 'models/model_config.pickle')\n",
    "new_weights = pull_data_from_s3(s3_client, bucket_name, 'models/model_weights.pickle')\n",
    "\n",
    "\n",
    "new_model = keras.Model.from_config(new_config)\n",
    "new_model.set_weights(new_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
